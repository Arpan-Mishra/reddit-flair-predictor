{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting the reddit post flair\n",
    "\n",
    "Source: https://towardsdatascience.com/multi-class-text-classification-with-scikit-learn-12f1e60e0a9f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Data Manipulation \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "# Data Visualisation \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Statistical libraries \n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "# Natural Language Processing\n",
    "import nltk \n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "# Machine Learning \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Performance Evaluation and Support\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1650, 11)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data into the dataframe \n",
    "data = pd.read_csv('data.csv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Title</th>\n",
       "      <th>Score</th>\n",
       "      <th>ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>created_on</th>\n",
       "      <th>Body</th>\n",
       "      <th>Original</th>\n",
       "      <th>Flair</th>\n",
       "      <th>Comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Lost my Job, Sick Mother and Paralysed Dad, In...</td>\n",
       "      <td>1046</td>\n",
       "      <td>g014wc</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/g014wc...</td>\n",
       "      <td>134</td>\n",
       "      <td>1.586742e+09</td>\n",
       "      <td>Hi....It's really tough time for everyone. I r...</td>\n",
       "      <td>False</td>\n",
       "      <td>AskIndia</td>\n",
       "      <td>Learn Python, then Django. Php might take a lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Why does the government come with a begging bo...</td>\n",
       "      <td>645</td>\n",
       "      <td>fxofyu</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/fxofyu...</td>\n",
       "      <td>204</td>\n",
       "      <td>1.586448e+09</td>\n",
       "      <td>We have floods, terrorist attacks, famines due...</td>\n",
       "      <td>False</td>\n",
       "      <td>AskIndia</td>\n",
       "      <td>[removed]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Mother's condition is going worse due to hepat...</td>\n",
       "      <td>764</td>\n",
       "      <td>g0zlly</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/g0zlly...</td>\n",
       "      <td>94</td>\n",
       "      <td>1.586871e+09</td>\n",
       "      <td>Hi folks, I really appreciate the warm respons...</td>\n",
       "      <td>False</td>\n",
       "      <td>AskIndia</td>\n",
       "      <td>Can I get some updates and verification on thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>People stuck with their family during the lock...</td>\n",
       "      <td>157</td>\n",
       "      <td>g4lrhm</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/g4lrhm...</td>\n",
       "      <td>117</td>\n",
       "      <td>1.587384e+09</td>\n",
       "      <td>I don't think we've spend so much time with fa...</td>\n",
       "      <td>False</td>\n",
       "      <td>AskIndia</td>\n",
       "      <td>&gt;patriarchal father who could care less etc  \\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Men who are 30+ and have decided not to get ma...</td>\n",
       "      <td>267</td>\n",
       "      <td>fvy95j</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/fvy95j...</td>\n",
       "      <td>206</td>\n",
       "      <td>1.586207e+09</td>\n",
       "      <td>The corona virus has given me some time to thi...</td>\n",
       "      <td>False</td>\n",
       "      <td>AskIndia</td>\n",
       "      <td>Get married. Indians are genetically engineere...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              Title  Score  \\\n",
       "0           0  Lost my Job, Sick Mother and Paralysed Dad, In...   1046   \n",
       "1           1  Why does the government come with a begging bo...    645   \n",
       "2           2  Mother's condition is going worse due to hepat...    764   \n",
       "3           3  People stuck with their family during the lock...    157   \n",
       "4           4  Men who are 30+ and have decided not to get ma...    267   \n",
       "\n",
       "       ID                                                URL  num_comments  \\\n",
       "0  g014wc  https://www.reddit.com/r/india/comments/g014wc...           134   \n",
       "1  fxofyu  https://www.reddit.com/r/india/comments/fxofyu...           204   \n",
       "2  g0zlly  https://www.reddit.com/r/india/comments/g0zlly...            94   \n",
       "3  g4lrhm  https://www.reddit.com/r/india/comments/g4lrhm...           117   \n",
       "4  fvy95j  https://www.reddit.com/r/india/comments/fvy95j...           206   \n",
       "\n",
       "     created_on                                               Body  Original  \\\n",
       "0  1.586742e+09  Hi....It's really tough time for everyone. I r...     False   \n",
       "1  1.586448e+09  We have floods, terrorist attacks, famines due...     False   \n",
       "2  1.586871e+09  Hi folks, I really appreciate the warm respons...     False   \n",
       "3  1.587384e+09  I don't think we've spend so much time with fa...     False   \n",
       "4  1.586207e+09  The corona virus has given me some time to thi...     False   \n",
       "\n",
       "      Flair                                           Comments  \n",
       "0  AskIndia  Learn Python, then Django. Php might take a lo...  \n",
       "1  AskIndia                                         [removed]   \n",
       "2  AskIndia  Can I get some updates and verification on thi...  \n",
       "3  AskIndia  >patriarchal father who could care less etc  \\...  \n",
       "4  AskIndia  Get married. Indians are genetically engineere...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initial look at the data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1650 entries, 0 to 1649\n",
      "Data columns (total 11 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Unnamed: 0    1650 non-null   int64  \n",
      " 1   Title         1650 non-null   object \n",
      " 2   Score         1650 non-null   int64  \n",
      " 3   ID            1650 non-null   object \n",
      " 4   URL           1650 non-null   object \n",
      " 5   num_comments  1650 non-null   int64  \n",
      " 6   created_on    1650 non-null   float64\n",
      " 7   Body          635 non-null    object \n",
      " 8   Original      1650 non-null   bool   \n",
      " 9   Flair         1650 non-null   object \n",
      " 10  Comments      1557 non-null   object \n",
      "dtypes: bool(1), float64(1), int64(3), object(6)\n",
      "memory usage: 130.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# Printing the data info to have a look at the null values and data types\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset does not have any null values for the flairs. There are null values only in Comments and Body. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1650 entries, 0 to 1649\n",
      "Data columns (total 11 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Unnamed: 0    1650 non-null   int64  \n",
      " 1   Title         1650 non-null   object \n",
      " 2   Score         1650 non-null   int64  \n",
      " 3   ID            1650 non-null   object \n",
      " 4   URL           1650 non-null   object \n",
      " 5   num_comments  1650 non-null   int64  \n",
      " 6   created_on    1650 non-null   float64\n",
      " 7   Body          635 non-null    object \n",
      " 8   Original      1650 non-null   bool   \n",
      " 9   Flair         1650 non-null   object \n",
      " 10  Comments      1557 non-null   object \n",
      "dtypes: bool(1), float64(1), int64(3), object(6)\n",
      "memory usage: 130.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# Printing the info will show 987 not null rows\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a copy of the data for later use\n",
    "data_og = data.copy()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of relevant features (MOVE LATER)\n",
    "features = ['Flair', 'URL', 'Title', 'Comments', 'Body']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first task is creating a set of labels and assigning them numbers for each unique flair. So, we can first extract the flair data and then assign them integer numbers. This will also include alloting repetitive and similar flairs same labels. We will be adding a new column `id` which is not equivalent to the original ID, hence I am calling it id.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Flair</th>\n",
       "      <th>URL</th>\n",
       "      <th>Title</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AskIndia</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/g014wc...</td>\n",
       "      <td>Lost my Job, Sick Mother and Paralysed Dad, In...</td>\n",
       "      <td>Learn Python, then Django. Php might take a lo...</td>\n",
       "      <td>Hi....It's really tough time for everyone. I r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AskIndia</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/fxofyu...</td>\n",
       "      <td>Why does the government come with a begging bo...</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>We have floods, terrorist attacks, famines due...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AskIndia</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/g0zlly...</td>\n",
       "      <td>Mother's condition is going worse due to hepat...</td>\n",
       "      <td>Can I get some updates and verification on thi...</td>\n",
       "      <td>Hi folks, I really appreciate the warm respons...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AskIndia</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/g4lrhm...</td>\n",
       "      <td>People stuck with their family during the lock...</td>\n",
       "      <td>&gt;patriarchal father who could care less etc  \\...</td>\n",
       "      <td>I don't think we've spend so much time with fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AskIndia</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/fvy95j...</td>\n",
       "      <td>Men who are 30+ and have decided not to get ma...</td>\n",
       "      <td>Get married. Indians are genetically engineere...</td>\n",
       "      <td>The corona virus has given me some time to thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1645</th>\n",
       "      <td>AMA</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/2oytx7...</td>\n",
       "      <td>IAMA person suffering from Bipola[r] Disorder....</td>\n",
       "      <td>Is your zodiac sign Gemini?</td>\n",
       "      <td>Hi all. I alternate between feeling like Einst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1646</th>\n",
       "      <td>AMA</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/4bmka5...</td>\n",
       "      <td>Identity, policy, and privacy</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>Hi Reddit community! It’s a pleasure to be her...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1647</th>\n",
       "      <td>AMA</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/3rhufx...</td>\n",
       "      <td>Hi /r/India, I am cartoonist Sumit Kumar autho...</td>\n",
       "      <td>late to the party and i have no questions for ...</td>\n",
       "      <td>Edit : Going to sleep now. Big dhanyawaad for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1648</th>\n",
       "      <td>AMA</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/4yc03a...</td>\n",
       "      <td>Hi Reddit, this is XUlrike from Janwaar Castle...</td>\n",
       "      <td>[Your organization’s logo](https://janwaar-cas...</td>\n",
       "      <td>The purpose of the Janwaar Castle Community Or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1649</th>\n",
       "      <td>AMA</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/4vs9fj...</td>\n",
       "      <td>Hey guys, I am Harsh Rajat, started my entrepr...</td>\n",
       "      <td>Okay then! this seems weird, more than that sh...</td>\n",
       "      <td>About Me: A little backstory about me: I start...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1650 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Flair                                                URL  \\\n",
       "0     AskIndia  https://www.reddit.com/r/india/comments/g014wc...   \n",
       "1     AskIndia  https://www.reddit.com/r/india/comments/fxofyu...   \n",
       "2     AskIndia  https://www.reddit.com/r/india/comments/g0zlly...   \n",
       "3     AskIndia  https://www.reddit.com/r/india/comments/g4lrhm...   \n",
       "4     AskIndia  https://www.reddit.com/r/india/comments/fvy95j...   \n",
       "...        ...                                                ...   \n",
       "1645       AMA  https://www.reddit.com/r/india/comments/2oytx7...   \n",
       "1646       AMA  https://www.reddit.com/r/india/comments/4bmka5...   \n",
       "1647       AMA  https://www.reddit.com/r/india/comments/3rhufx...   \n",
       "1648       AMA  https://www.reddit.com/r/india/comments/4yc03a...   \n",
       "1649       AMA  https://www.reddit.com/r/india/comments/4vs9fj...   \n",
       "\n",
       "                                                  Title  \\\n",
       "0     Lost my Job, Sick Mother and Paralysed Dad, In...   \n",
       "1     Why does the government come with a begging bo...   \n",
       "2     Mother's condition is going worse due to hepat...   \n",
       "3     People stuck with their family during the lock...   \n",
       "4     Men who are 30+ and have decided not to get ma...   \n",
       "...                                                 ...   \n",
       "1645  IAMA person suffering from Bipola[r] Disorder....   \n",
       "1646                      Identity, policy, and privacy   \n",
       "1647  Hi /r/India, I am cartoonist Sumit Kumar autho...   \n",
       "1648  Hi Reddit, this is XUlrike from Janwaar Castle...   \n",
       "1649  Hey guys, I am Harsh Rajat, started my entrepr...   \n",
       "\n",
       "                                               Comments  \\\n",
       "0     Learn Python, then Django. Php might take a lo...   \n",
       "1                                            [removed]    \n",
       "2     Can I get some updates and verification on thi...   \n",
       "3     >patriarchal father who could care less etc  \\...   \n",
       "4     Get married. Indians are genetically engineere...   \n",
       "...                                                 ...   \n",
       "1645                      Is your zodiac sign Gemini?     \n",
       "1646                                         [deleted]    \n",
       "1647  late to the party and i have no questions for ...   \n",
       "1648  [Your organization’s logo](https://janwaar-cas...   \n",
       "1649  Okay then! this seems weird, more than that sh...   \n",
       "\n",
       "                                                   Body  \n",
       "0     Hi....It's really tough time for everyone. I r...  \n",
       "1     We have floods, terrorist attacks, famines due...  \n",
       "2     Hi folks, I really appreciate the warm respons...  \n",
       "3     I don't think we've spend so much time with fa...  \n",
       "4     The corona virus has given me some time to thi...  \n",
       "...                                                 ...  \n",
       "1645  Hi all. I alternate between feeling like Einst...  \n",
       "1646  Hi Reddit community! It’s a pleasure to be her...  \n",
       "1647  Edit : Going to sleep now. Big dhanyawaad for ...  \n",
       "1648  The purpose of the Janwaar Castle Community Or...  \n",
       "1649  About Me: A little backstory about me: I start...  \n",
       "\n",
       "[1650 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collecting the flair and ids\n",
    "data = data[features]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Flair</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AskIndia</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>Non-Political</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>[R]eddiquette</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>Photography</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>Science/Technology</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>Politics</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>Business/Finance</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050</th>\n",
       "      <td>Policy/Economy</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1200</th>\n",
       "      <td>Sports</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1350</th>\n",
       "      <td>Food</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1500</th>\n",
       "      <td>AMA</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Flair  id\n",
       "0               AskIndia   0\n",
       "150        Non-Political   1\n",
       "300        [R]eddiquette   2\n",
       "450          Photography   3\n",
       "600   Science/Technology   4\n",
       "750             Politics   5\n",
       "900     Business/Finance   6\n",
       "1050      Policy/Economy   7\n",
       "1200              Sports   8\n",
       "1350                Food   9\n",
       "1500                 AMA  10"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assigning and individual id to each flair\n",
    "data['id'] = data['Flair'].factorize()[0]\n",
    "flair_category = data[['Flair', 'id']].drop_duplicates().sort_values('id')\n",
    "flair_category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to print individual strings to make sure that we are comparing the strings accurately. This means that some strings may have a space here and there and we need to get rid of that or take that into account. I could have used str.contains as well but I prefer this method for the sake of accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AskIndia': 0, 'Non-Political': 1, '[R]eddiquette': 2, 'Photography': 3, 'Science/Technology': 4, 'Politics': 5, 'Business/Finance': 6, 'Policy/Economy': 7, 'Sports': 8, 'Food': 9, 'AMA': 10}\n"
     ]
    }
   ],
   "source": [
    "# Convert into a label dctionary to be used as a means of assigning labels after the prediction\n",
    "category_labels = dict(flair_category.values)\n",
    "print(category_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'AskIndia', 1: 'Non-Political', 2: '[R]eddiquette', 3: 'Photography', 4: 'Science/Technology', 5: 'Politics', 6: 'Business/Finance', 7: 'Policy/Economy', 8: 'Sports', 9: 'Food', 10: 'AMA'}\n"
     ]
    }
   ],
   "source": [
    "# Similarly, we can create an inverse of the previouus one to convert labels to categories\n",
    "category_reverse = dict(flair_category[['id', 'Flair']].values)\n",
    "print(category_reverse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look at the data now. We have an id column which are basically the labels that we have to predict. They are derived from equivalent flair categories. We will be using the other columns as our input features. We will also create a series of all labels that need to predicted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Flair</th>\n",
       "      <th>URL</th>\n",
       "      <th>Title</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Body</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AskIndia</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/g014wc...</td>\n",
       "      <td>Lost my Job, Sick Mother and Paralysed Dad, In...</td>\n",
       "      <td>Learn Python, then Django. Php might take a lo...</td>\n",
       "      <td>Hi....It's really tough time for everyone. I r...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AskIndia</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/fxofyu...</td>\n",
       "      <td>Why does the government come with a begging bo...</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>We have floods, terrorist attacks, famines due...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AskIndia</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/g0zlly...</td>\n",
       "      <td>Mother's condition is going worse due to hepat...</td>\n",
       "      <td>Can I get some updates and verification on thi...</td>\n",
       "      <td>Hi folks, I really appreciate the warm respons...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AskIndia</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/g4lrhm...</td>\n",
       "      <td>People stuck with their family during the lock...</td>\n",
       "      <td>&gt;patriarchal father who could care less etc  \\...</td>\n",
       "      <td>I don't think we've spend so much time with fa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AskIndia</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/fvy95j...</td>\n",
       "      <td>Men who are 30+ and have decided not to get ma...</td>\n",
       "      <td>Get married. Indians are genetically engineere...</td>\n",
       "      <td>The corona virus has given me some time to thi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AskIndia</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/g1lmhg...</td>\n",
       "      <td>[Please Advice] Reality punched me in the face...</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>Sorry Reddit, this post is going to be long. P...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AskIndia</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/g42vfo...</td>\n",
       "      <td>What is the PM CARES fund being used for? how ...</td>\n",
       "      <td>Someone had created a petition for this on cha...</td>\n",
       "      <td>In this need of the hour, many citizens are co...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AskIndia</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/g0igt7...</td>\n",
       "      <td>r/India: If money is no bar, would you prefer ...</td>\n",
       "      <td>This kind of questions are always asked and an...</td>\n",
       "      <td>Seems like everybody here is very critical of ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AskIndia</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/g590ut...</td>\n",
       "      <td>So, I'm an American dating a South Indian, and...</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>So, I'm dating a grad student from Coimbature....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AskIndia</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/g2xjhd...</td>\n",
       "      <td>Any idea what has happened to quora</td>\n",
       "      <td>It's quite ironic this post comming from r/india</td>\n",
       "      <td>Hey guys. I used to read a lot on quora before...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Flair                                                URL  \\\n",
       "0  AskIndia  https://www.reddit.com/r/india/comments/g014wc...   \n",
       "1  AskIndia  https://www.reddit.com/r/india/comments/fxofyu...   \n",
       "2  AskIndia  https://www.reddit.com/r/india/comments/g0zlly...   \n",
       "3  AskIndia  https://www.reddit.com/r/india/comments/g4lrhm...   \n",
       "4  AskIndia  https://www.reddit.com/r/india/comments/fvy95j...   \n",
       "5  AskIndia  https://www.reddit.com/r/india/comments/g1lmhg...   \n",
       "6  AskIndia  https://www.reddit.com/r/india/comments/g42vfo...   \n",
       "7  AskIndia  https://www.reddit.com/r/india/comments/g0igt7...   \n",
       "8  AskIndia  https://www.reddit.com/r/india/comments/g590ut...   \n",
       "9  AskIndia  https://www.reddit.com/r/india/comments/g2xjhd...   \n",
       "\n",
       "                                               Title  \\\n",
       "0  Lost my Job, Sick Mother and Paralysed Dad, In...   \n",
       "1  Why does the government come with a begging bo...   \n",
       "2  Mother's condition is going worse due to hepat...   \n",
       "3  People stuck with their family during the lock...   \n",
       "4  Men who are 30+ and have decided not to get ma...   \n",
       "5  [Please Advice] Reality punched me in the face...   \n",
       "6  What is the PM CARES fund being used for? how ...   \n",
       "7  r/India: If money is no bar, would you prefer ...   \n",
       "8  So, I'm an American dating a South Indian, and...   \n",
       "9                Any idea what has happened to quora   \n",
       "\n",
       "                                            Comments  \\\n",
       "0  Learn Python, then Django. Php might take a lo...   \n",
       "1                                         [removed]    \n",
       "2  Can I get some updates and verification on thi...   \n",
       "3  >patriarchal father who could care less etc  \\...   \n",
       "4  Get married. Indians are genetically engineere...   \n",
       "5                                         [deleted]    \n",
       "6  Someone had created a petition for this on cha...   \n",
       "7  This kind of questions are always asked and an...   \n",
       "8                                         [removed]    \n",
       "9  It's quite ironic this post comming from r/india    \n",
       "\n",
       "                                                Body  id  \n",
       "0  Hi....It's really tough time for everyone. I r...   0  \n",
       "1  We have floods, terrorist attacks, famines due...   0  \n",
       "2  Hi folks, I really appreciate the warm respons...   0  \n",
       "3  I don't think we've spend so much time with fa...   0  \n",
       "4  The corona virus has given me some time to thi...   0  \n",
       "5  Sorry Reddit, this post is going to be long. P...   0  \n",
       "6  In this need of the hour, many citizens are co...   0  \n",
       "7  Seems like everybody here is very critical of ...   0  \n",
       "8  So, I'm dating a grad student from Coimbature....   0  \n",
       "9  Hey guys. I used to read a lot on quora before...   0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = data['id']\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing text analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "# Import nltk stopwords as done in the previous notebook as well\n",
    "STOPWORDS = nltk.corpus.stopwords.words('english')\n",
    "print(STOPWORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import nltk punctuation which will be removed from our texts as well\n",
    "# nltk.download('punkt')\n",
    "# PUNCT = nltk.corpus.stopwords.words('punkt')\n",
    "# print(PUNCT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this, I will be combining the data present in the body, Title and the Comments. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is giving me a very weird problem. \n",
    "All comparison with nan are returning to be false. np.NaN is not working so I am trying a different approach. I am comparing the value with float or str to determine the existence of null value. Float = Null. str = something is present. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for i in range(len(data)):\n",
    "#     print(type(data.iloc[i]['Body']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prakhar/.local/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "/home/prakhar/.local/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Flair</th>\n",
       "      <th>URL</th>\n",
       "      <th>Title</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Body</th>\n",
       "      <th>id</th>\n",
       "      <th>Combine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AskIndia</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/g014wc...</td>\n",
       "      <td>Lost my Job, Sick Mother and Paralysed Dad, In...</td>\n",
       "      <td>Learn Python, then Django. Php might take a lo...</td>\n",
       "      <td>Hi....It's really tough time for everyone. I r...</td>\n",
       "      <td>0</td>\n",
       "      <td>Lost my Job, Sick Mother and Paralysed Dad, In...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AskIndia</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/fxofyu...</td>\n",
       "      <td>Why does the government come with a begging bo...</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>We have floods, terrorist attacks, famines due...</td>\n",
       "      <td>0</td>\n",
       "      <td>Why does the government come with a begging bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AskIndia</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/g0zlly...</td>\n",
       "      <td>Mother's condition is going worse due to hepat...</td>\n",
       "      <td>Can I get some updates and verification on thi...</td>\n",
       "      <td>Hi folks, I really appreciate the warm respons...</td>\n",
       "      <td>0</td>\n",
       "      <td>Mother's condition is going worse due to hepat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AskIndia</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/g4lrhm...</td>\n",
       "      <td>People stuck with their family during the lock...</td>\n",
       "      <td>&gt;patriarchal father who could care less etc  \\...</td>\n",
       "      <td>I don't think we've spend so much time with fa...</td>\n",
       "      <td>0</td>\n",
       "      <td>People stuck with their family during the lock...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AskIndia</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/fvy95j...</td>\n",
       "      <td>Men who are 30+ and have decided not to get ma...</td>\n",
       "      <td>Get married. Indians are genetically engineere...</td>\n",
       "      <td>The corona virus has given me some time to thi...</td>\n",
       "      <td>0</td>\n",
       "      <td>Men who are 30+ and have decided not to get ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AskIndia</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/g1lmhg...</td>\n",
       "      <td>[Please Advice] Reality punched me in the face...</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>Sorry Reddit, this post is going to be long. P...</td>\n",
       "      <td>0</td>\n",
       "      <td>[Please Advice] Reality punched me in the face...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AskIndia</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/g42vfo...</td>\n",
       "      <td>What is the PM CARES fund being used for? how ...</td>\n",
       "      <td>Someone had created a petition for this on cha...</td>\n",
       "      <td>In this need of the hour, many citizens are co...</td>\n",
       "      <td>0</td>\n",
       "      <td>What is the PM CARES fund being used for? how ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AskIndia</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/g0igt7...</td>\n",
       "      <td>r/India: If money is no bar, would you prefer ...</td>\n",
       "      <td>This kind of questions are always asked and an...</td>\n",
       "      <td>Seems like everybody here is very critical of ...</td>\n",
       "      <td>0</td>\n",
       "      <td>r/India: If money is no bar, would you prefer ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AskIndia</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/g590ut...</td>\n",
       "      <td>So, I'm an American dating a South Indian, and...</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>So, I'm dating a grad student from Coimbature....</td>\n",
       "      <td>0</td>\n",
       "      <td>So, I'm an American dating a South Indian, and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AskIndia</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/g2xjhd...</td>\n",
       "      <td>Any idea what has happened to quora</td>\n",
       "      <td>It's quite ironic this post comming from r/india</td>\n",
       "      <td>Hey guys. I used to read a lot on quora before...</td>\n",
       "      <td>0</td>\n",
       "      <td>Any idea what has happened to quora Hey guys. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AskIndia</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/fx29yh...</td>\n",
       "      <td>She is leaving me because of me being poor wha...</td>\n",
       "      <td>let her make her choice. You, Take time become...</td>\n",
       "      <td>Sorry for poor formatting I am on phone.\\n\\n\\n...</td>\n",
       "      <td>0</td>\n",
       "      <td>She is leaving me because of me being poor wha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AskIndia</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/g0ybrw...</td>\n",
       "      <td>Got struck by a cop today</td>\n",
       "      <td>&gt; I can't help but rationlize why I was struck...</td>\n",
       "      <td>I was out to get some meds for my mentally and...</td>\n",
       "      <td>0</td>\n",
       "      <td>Got struck by a cop today I was out to get som...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AskIndia</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/g5t7ps...</td>\n",
       "      <td>People of r/india, how is your Work from Home ...</td>\n",
       "      <td>wfh is worst, boring.</td>\n",
       "      <td>Just interested in how WFH is actually coming ...</td>\n",
       "      <td>0</td>\n",
       "      <td>People of r/india, how is your Work from Home ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>AskIndia</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/g2zwkc...</td>\n",
       "      <td>How much yelling is normal for Indians? Is it ...</td>\n",
       "      <td>Are you a guy or a girl though? Cuz being a gi...</td>\n",
       "      <td>My Norwegian boyfriend says I yell too much, a...</td>\n",
       "      <td>0</td>\n",
       "      <td>How much yelling is normal for Indians? Is it ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>AskIndia</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/fxq3g9...</td>\n",
       "      <td>Urgent, please help</td>\n",
       "      <td>Please tell your dad to write letters to the c...</td>\n",
       "      <td>My dad is stuck in Madhya Pradesh (Shahdole), ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Urgent, please help My dad is stuck in Madhya ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>AskIndia</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/g46wcl...</td>\n",
       "      <td>Skincare India, what are your holy grail produ...</td>\n",
       "      <td>Anything more than washing my face twice daily...</td>\n",
       "      <td>Hey guys, didn't know if there's a specific su...</td>\n",
       "      <td>0</td>\n",
       "      <td>Skincare India, what are your holy grail produ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>AskIndia</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/g2hqbx...</td>\n",
       "      <td>Did Ramayana actually happen in reality? Are t...</td>\n",
       "      <td>The only approach i can think of is , checking...</td>\n",
       "      <td>Is it just me or all this looks really unbelie...</td>\n",
       "      <td>0</td>\n",
       "      <td>Did Ramayana actually happen in reality? Are t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>AskIndia</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/g1aj5a...</td>\n",
       "      <td>[Serious] How is your relationship with your p...</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>I feel a lot of social problems in India can b...</td>\n",
       "      <td>0</td>\n",
       "      <td>[Serious] How is your relationship with your p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>AskIndia</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/fv8lt3...</td>\n",
       "      <td>My plan for 5th April, 9PM is to switch all li...</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>I don't like to worship leaders. And not at al...</td>\n",
       "      <td>0</td>\n",
       "      <td>My plan for 5th April, 9PM is to switch all li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>AskIndia</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/g358tp...</td>\n",
       "      <td>How much money should an average Indian youth ...</td>\n",
       "      <td>less than 15k .</td>\n",
       "      <td>I am an average Indian youth. I got an entry l...</td>\n",
       "      <td>0</td>\n",
       "      <td>How much money should an average Indian youth ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Flair                                                URL  \\\n",
       "0   AskIndia  https://www.reddit.com/r/india/comments/g014wc...   \n",
       "1   AskIndia  https://www.reddit.com/r/india/comments/fxofyu...   \n",
       "2   AskIndia  https://www.reddit.com/r/india/comments/g0zlly...   \n",
       "3   AskIndia  https://www.reddit.com/r/india/comments/g4lrhm...   \n",
       "4   AskIndia  https://www.reddit.com/r/india/comments/fvy95j...   \n",
       "5   AskIndia  https://www.reddit.com/r/india/comments/g1lmhg...   \n",
       "6   AskIndia  https://www.reddit.com/r/india/comments/g42vfo...   \n",
       "7   AskIndia  https://www.reddit.com/r/india/comments/g0igt7...   \n",
       "8   AskIndia  https://www.reddit.com/r/india/comments/g590ut...   \n",
       "9   AskIndia  https://www.reddit.com/r/india/comments/g2xjhd...   \n",
       "10  AskIndia  https://www.reddit.com/r/india/comments/fx29yh...   \n",
       "11  AskIndia  https://www.reddit.com/r/india/comments/g0ybrw...   \n",
       "12  AskIndia  https://www.reddit.com/r/india/comments/g5t7ps...   \n",
       "13  AskIndia  https://www.reddit.com/r/india/comments/g2zwkc...   \n",
       "14  AskIndia  https://www.reddit.com/r/india/comments/fxq3g9...   \n",
       "15  AskIndia  https://www.reddit.com/r/india/comments/g46wcl...   \n",
       "16  AskIndia  https://www.reddit.com/r/india/comments/g2hqbx...   \n",
       "17  AskIndia  https://www.reddit.com/r/india/comments/g1aj5a...   \n",
       "18  AskIndia  https://www.reddit.com/r/india/comments/fv8lt3...   \n",
       "19  AskIndia  https://www.reddit.com/r/india/comments/g358tp...   \n",
       "\n",
       "                                                Title  \\\n",
       "0   Lost my Job, Sick Mother and Paralysed Dad, In...   \n",
       "1   Why does the government come with a begging bo...   \n",
       "2   Mother's condition is going worse due to hepat...   \n",
       "3   People stuck with their family during the lock...   \n",
       "4   Men who are 30+ and have decided not to get ma...   \n",
       "5   [Please Advice] Reality punched me in the face...   \n",
       "6   What is the PM CARES fund being used for? how ...   \n",
       "7   r/India: If money is no bar, would you prefer ...   \n",
       "8   So, I'm an American dating a South Indian, and...   \n",
       "9                 Any idea what has happened to quora   \n",
       "10  She is leaving me because of me being poor wha...   \n",
       "11                          Got struck by a cop today   \n",
       "12  People of r/india, how is your Work from Home ...   \n",
       "13  How much yelling is normal for Indians? Is it ...   \n",
       "14                                Urgent, please help   \n",
       "15  Skincare India, what are your holy grail produ...   \n",
       "16  Did Ramayana actually happen in reality? Are t...   \n",
       "17  [Serious] How is your relationship with your p...   \n",
       "18  My plan for 5th April, 9PM is to switch all li...   \n",
       "19  How much money should an average Indian youth ...   \n",
       "\n",
       "                                             Comments  \\\n",
       "0   Learn Python, then Django. Php might take a lo...   \n",
       "1                                          [removed]    \n",
       "2   Can I get some updates and verification on thi...   \n",
       "3   >patriarchal father who could care less etc  \\...   \n",
       "4   Get married. Indians are genetically engineere...   \n",
       "5                                          [deleted]    \n",
       "6   Someone had created a petition for this on cha...   \n",
       "7   This kind of questions are always asked and an...   \n",
       "8                                          [removed]    \n",
       "9   It's quite ironic this post comming from r/india    \n",
       "10  let her make her choice. You, Take time become...   \n",
       "11  > I can't help but rationlize why I was struck...   \n",
       "12                             wfh is worst, boring.    \n",
       "13  Are you a guy or a girl though? Cuz being a gi...   \n",
       "14  Please tell your dad to write letters to the c...   \n",
       "15  Anything more than washing my face twice daily...   \n",
       "16  The only approach i can think of is , checking...   \n",
       "17                                         [deleted]    \n",
       "18                                         [deleted]    \n",
       "19                                   less than 15k .    \n",
       "\n",
       "                                                 Body  id  \\\n",
       "0   Hi....It's really tough time for everyone. I r...   0   \n",
       "1   We have floods, terrorist attacks, famines due...   0   \n",
       "2   Hi folks, I really appreciate the warm respons...   0   \n",
       "3   I don't think we've spend so much time with fa...   0   \n",
       "4   The corona virus has given me some time to thi...   0   \n",
       "5   Sorry Reddit, this post is going to be long. P...   0   \n",
       "6   In this need of the hour, many citizens are co...   0   \n",
       "7   Seems like everybody here is very critical of ...   0   \n",
       "8   So, I'm dating a grad student from Coimbature....   0   \n",
       "9   Hey guys. I used to read a lot on quora before...   0   \n",
       "10  Sorry for poor formatting I am on phone.\\n\\n\\n...   0   \n",
       "11  I was out to get some meds for my mentally and...   0   \n",
       "12  Just interested in how WFH is actually coming ...   0   \n",
       "13  My Norwegian boyfriend says I yell too much, a...   0   \n",
       "14  My dad is stuck in Madhya Pradesh (Shahdole), ...   0   \n",
       "15  Hey guys, didn't know if there's a specific su...   0   \n",
       "16  Is it just me or all this looks really unbelie...   0   \n",
       "17  I feel a lot of social problems in India can b...   0   \n",
       "18  I don't like to worship leaders. And not at al...   0   \n",
       "19  I am an average Indian youth. I got an entry l...   0   \n",
       "\n",
       "                                              Combine  \n",
       "0   Lost my Job, Sick Mother and Paralysed Dad, In...  \n",
       "1   Why does the government come with a begging bo...  \n",
       "2   Mother's condition is going worse due to hepat...  \n",
       "3   People stuck with their family during the lock...  \n",
       "4   Men who are 30+ and have decided not to get ma...  \n",
       "5   [Please Advice] Reality punched me in the face...  \n",
       "6   What is the PM CARES fund being used for? how ...  \n",
       "7   r/India: If money is no bar, would you prefer ...  \n",
       "8   So, I'm an American dating a South Indian, and...  \n",
       "9   Any idea what has happened to quora Hey guys. ...  \n",
       "10  She is leaving me because of me being poor wha...  \n",
       "11  Got struck by a cop today I was out to get som...  \n",
       "12  People of r/india, how is your Work from Home ...  \n",
       "13  How much yelling is normal for Indians? Is it ...  \n",
       "14  Urgent, please help My dad is stuck in Madhya ...  \n",
       "15  Skincare India, what are your holy grail produ...  \n",
       "16  Did Ramayana actually happen in reality? Are t...  \n",
       "17  [Serious] How is your relationship with your p...  \n",
       "18  My plan for 5th April, 9PM is to switch all li...  \n",
       "19  How much money should an average Indian youth ...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Combine'] = data['Title'] # Create a column combined\n",
    "count = 0\n",
    "for i in range(len(data)):\n",
    "    if type(data.loc[i]['Body']) != float:\n",
    "        data['Combine'][i] = data['Combine'][i] + ' ' + data['Body'][i]\n",
    "\n",
    "    if type(data.loc[i]['Comments']) != float:\n",
    "        data['Combine'][i] = data['Combine'][i] + ' ' + data['Comments'][i]\n",
    "\n",
    "data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1650 entries, 0 to 1649\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Flair     1650 non-null   object\n",
      " 1   URL       1650 non-null   object\n",
      " 2   Title     1650 non-null   object\n",
      " 3   Comments  1557 non-null   object\n",
      " 4   Body      635 non-null    object\n",
      " 5   id        1650 non-null   int64 \n",
      " 6   Combine   1650 non-null   object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 90.4+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Solve my family dispute! In my country, the quarantine began nearly around 15 march and I've been home since then along with my brother, mother, father and grandmother. My father has been abusing all of us mentally since the quarantine began and Today he tried to beat the three of us (me, brother and mother) with a stick but we were successfully able to defend but got minor injuries and then the community people arrived. And somehow the dispute was solved ( as we all thought ) but since then he's really angry and I'm truly afraid of my life. He threatened that he'll kill us and all of my mother's family. Please guide me on how to get help and solve this! I'm unable to understand who to contact and how to go forward. My mother has agreed for a divorce but we'll apply for that once this gets over.\\nPlease don't joke around as I'm genuinely afraid and I'm literally crying and shaking all the time.\\n\\nFollow up because a lot of people are talking about calling the police: We called the police but the people told us to not file anything and we didn't because they said my dad's really sorry and all that shit. But when we came back to the house he showed off that he was to everyone so we calmed down, but now when everyone is gone, he's back to his true self. I'm really looking forward to filing that report if he tries anything, but I'm afraid that he'll kill us the next time. Talk to the police about this. Get some advice. If you are the eldest son please reassure your brother that evrything will be okay. And also your mother. Have been through this. And it takes a toll on the mental stability of the young ones. Be strong for both ur mom Nd brother. Its tough but thts life. You will get through this. Get help from neighbours too. They can be witnesses. Stay strong. \""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[34]['Combine']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning our data that will be used as an input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPLACE_SPACES = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS = re.compile('[^0-9a-z #+_]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are certain symbols which add no analytical value to the data. Similarly, there certain areas where there are extra spaces or bracket spaces which are being being substituted by just one space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    '''\n",
    "        text: a string\n",
    "        \n",
    "        return: modified initial string\n",
    "        \n",
    "    '''\n",
    "\n",
    "    text = text.lower() # lowercase text\n",
    "    text = REPLACE_SPACES.sub(' ', text) \n",
    "    text = BAD_SYMBOLS.sub('', text) # Replace Bad Symbols which \n",
    "    text = text.replace('x', '')\n",
    "    \n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # remove stopwors from text\n",
    "    return text\n",
    "\n",
    "data['Combine'] = data['Combine'].apply(clean_text)\n",
    "data['Combine'] = data['Combine'].str.replace('\\d+', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       lost job sick mother paralysed dad lockdown ea...\n",
       "1       government come begging bowl every crisis floo...\n",
       "2       mothers condition going worse due hepatitis b ...\n",
       "3       people stuck family lockdown family falling ap...\n",
       "4       men + decided get married plan old age corona ...\n",
       "                              ...                        \n",
       "1645    iama person suffering bipola r disorder ama hi...\n",
       "1646    identity policy privacy hi reddit community pl...\n",
       "1647    hi r india cartoonist sumit kumar author amar ...\n",
       "1648    hi reddit ulrike janwaar castle ask anything p...\n",
       "1649    hey guys harsh rajat started entrepreneur jour...\n",
       "Name: Combine, Length: 1650, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Combine']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF Feature Importance\n",
    "\n",
    "TFIDF =  Term Frequency–Inverse Document Frequency.\n",
    "It is a numerical statistic that is intended to reflect how important a word is to a document in a collection or corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an instance of the Tfidf vectorizer\n",
    "# I will be performing a hyperparameter tuning soon\n",
    "tfidf = TfidfVectorizer(sublinear_tf=True, \n",
    "                        min_df=5, \n",
    "                        stop_words=STOPWORDS, \n",
    "                        norm = 'l2', \n",
    "                        encoding='latin-1', \n",
    "                        ngram_range=(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Flair</th>\n",
       "      <th>URL</th>\n",
       "      <th>Title</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Body</th>\n",
       "      <th>id</th>\n",
       "      <th>Combine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1645</th>\n",
       "      <td>AMA</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/2oytx7...</td>\n",
       "      <td>IAMA person suffering from Bipola[r] Disorder....</td>\n",
       "      <td>Is your zodiac sign Gemini?</td>\n",
       "      <td>Hi all. I alternate between feeling like Einst...</td>\n",
       "      <td>10</td>\n",
       "      <td>iama person suffering bipola r disorder ama hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1646</th>\n",
       "      <td>AMA</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/4bmka5...</td>\n",
       "      <td>Identity, policy, and privacy</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>Hi Reddit community! It’s a pleasure to be her...</td>\n",
       "      <td>10</td>\n",
       "      <td>identity policy privacy hi reddit community pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1647</th>\n",
       "      <td>AMA</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/3rhufx...</td>\n",
       "      <td>Hi /r/India, I am cartoonist Sumit Kumar autho...</td>\n",
       "      <td>late to the party and i have no questions for ...</td>\n",
       "      <td>Edit : Going to sleep now. Big dhanyawaad for ...</td>\n",
       "      <td>10</td>\n",
       "      <td>hi r india cartoonist sumit kumar author amar ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1648</th>\n",
       "      <td>AMA</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/4yc03a...</td>\n",
       "      <td>Hi Reddit, this is XUlrike from Janwaar Castle...</td>\n",
       "      <td>[Your organization’s logo](https://janwaar-cas...</td>\n",
       "      <td>The purpose of the Janwaar Castle Community Or...</td>\n",
       "      <td>10</td>\n",
       "      <td>hi reddit ulrike janwaar castle ask anything p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1649</th>\n",
       "      <td>AMA</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/4vs9fj...</td>\n",
       "      <td>Hey guys, I am Harsh Rajat, started my entrepr...</td>\n",
       "      <td>Okay then! this seems weird, more than that sh...</td>\n",
       "      <td>About Me: A little backstory about me: I start...</td>\n",
       "      <td>10</td>\n",
       "      <td>hey guys harsh rajat started entrepreneur jour...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Flair                                                URL  \\\n",
       "1645   AMA  https://www.reddit.com/r/india/comments/2oytx7...   \n",
       "1646   AMA  https://www.reddit.com/r/india/comments/4bmka5...   \n",
       "1647   AMA  https://www.reddit.com/r/india/comments/3rhufx...   \n",
       "1648   AMA  https://www.reddit.com/r/india/comments/4yc03a...   \n",
       "1649   AMA  https://www.reddit.com/r/india/comments/4vs9fj...   \n",
       "\n",
       "                                                  Title  \\\n",
       "1645  IAMA person suffering from Bipola[r] Disorder....   \n",
       "1646                      Identity, policy, and privacy   \n",
       "1647  Hi /r/India, I am cartoonist Sumit Kumar autho...   \n",
       "1648  Hi Reddit, this is XUlrike from Janwaar Castle...   \n",
       "1649  Hey guys, I am Harsh Rajat, started my entrepr...   \n",
       "\n",
       "                                               Comments  \\\n",
       "1645                      Is your zodiac sign Gemini?     \n",
       "1646                                         [deleted]    \n",
       "1647  late to the party and i have no questions for ...   \n",
       "1648  [Your organization’s logo](https://janwaar-cas...   \n",
       "1649  Okay then! this seems weird, more than that sh...   \n",
       "\n",
       "                                                   Body  id  \\\n",
       "1645  Hi all. I alternate between feeling like Einst...  10   \n",
       "1646  Hi Reddit community! It’s a pleasure to be her...  10   \n",
       "1647  Edit : Going to sleep now. Big dhanyawaad for ...  10   \n",
       "1648  The purpose of the Janwaar Castle Community Or...  10   \n",
       "1649  About Me: A little backstory about me: I start...  10   \n",
       "\n",
       "                                                Combine  \n",
       "1645  iama person suffering bipola r disorder ama hi...  \n",
       "1646  identity policy privacy hi reddit community pl...  \n",
       "1647  hi r india cartoonist sumit kumar author amar ...  \n",
       "1648  hi reddit ulrike janwaar castle ask anything p...  \n",
       "1649  hey guys harsh rajat started entrepreneur jour...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1650, 3297)\n"
     ]
    }
   ],
   "source": [
    "# Extracting the features by fitting the Vectorizer on our Title data because that has the description of the post\n",
    "feat = tfidf.fit_transform(data['Combine']).toarray()\n",
    "print(feat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I need to look at the most correlated words with each category and list them. I am gonna look at monograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Flair 'AMA':\n",
      "Most correlated unigrams:\n",
      "\t. hi\n",
      "\t. anything\n",
      "\t. ask\n",
      "\t. questions\n",
      "\t. ama\n",
      "\n",
      "Flair 'AskIndia':\n",
      "Most correlated unigrams:\n",
      "\t. advice\n",
      "\t. dad\n",
      "\t. situation\n",
      "\t. afraid\n",
      "\t. family\n",
      "\n",
      "Flair 'Business/Finance':\n",
      "Most correlated unigrams:\n",
      "\t. firms\n",
      "\t. emi\n",
      "\t. hdfc\n",
      "\t. mukesh\n",
      "\t. bank\n",
      "\n",
      "Flair 'Food':\n",
      "Most correlated unigrams:\n",
      "\t. restaurant\n",
      "\t. chutney\n",
      "\t. recipe\n",
      "\t. chicken\n",
      "\t. food\n",
      "\n",
      "Flair 'Non-Political':\n",
      "Most correlated unigrams:\n",
      "\t. rural\n",
      "\t. dads\n",
      "\t. found\n",
      "\t. bored\n",
      "\t. comics\n",
      "\n",
      "Flair 'Photography':\n",
      "Most correlated unigrams:\n",
      "\t. mm\n",
      "\t. beach\n",
      "\t. nikon\n",
      "\t. shot\n",
      "\t. oc\n",
      "\n",
      "Flair 'Policy/Economy':\n",
      "Most correlated unigrams:\n",
      "\t. gdp\n",
      "\t. govt\n",
      "\t. investments\n",
      "\t. nirmala\n",
      "\t. economy\n",
      "\n",
      "Flair 'Politics':\n",
      "Most correlated unigrams:\n",
      "\t. sonia\n",
      "\t. removed\n",
      "\t. modi\n",
      "\t. arnab\n",
      "\t. muslims\n",
      "\n",
      "Flair 'Science/Technology':\n",
      "Most correlated unigrams:\n",
      "\t. vpn\n",
      "\t. iit\n",
      "\t. develop\n",
      "\t. zoom\n",
      "\t. users\n",
      "\n",
      "Flair 'Sports':\n",
      "Most correlated unigrams:\n",
      "\t. ipl\n",
      "\t. football\n",
      "\t. sports\n",
      "\t. cricket\n",
      "\t. cup\n",
      "\n",
      "Flair '[R]eddiquette':\n",
      "Most correlated unigrams:\n",
      "\t. creator\n",
      "\t. boop\n",
      "\t. askaway\n",
      "\t. beep\n",
      "\t. bot\n"
     ]
    }
   ],
   "source": [
    "# chisq2 statistical test\n",
    "N = 5    # Number of examples to be listed\n",
    "for f, i in sorted(category_labels.items()):\n",
    "    chi2_feat = chi2(feat, labels == i)\n",
    "    indices = np.argsort(chi2_feat[0])\n",
    "    feat_names = np.array(tfidf.get_feature_names())[indices]\n",
    "    unigrams = [w for w in feat_names if len(w.split(' ')) == 1]\n",
    "    print(\"\\nFlair '{}':\".format(f))\n",
    "    print(\"Most correlated unigrams:\\n\\t. {}\".format('\\n\\t. '.join(unigrams[-N:])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Input Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AskIndia',\n",
       " 'Non-Political',\n",
       " '[R]eddiquette',\n",
       " 'Photography',\n",
       " 'Science/Technology',\n",
       " 'Politics',\n",
       " 'Business/Finance',\n",
       " 'Policy/Economy',\n",
       " 'Sports',\n",
       " 'Food',\n",
       " 'AMA']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flair_list = list(category_labels.keys())\n",
    "flair_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1402,) (1402,) (248,) (248,)\n"
     ]
    }
   ],
   "source": [
    "# Splitting 20% of the data into train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['Combine'], data['Flair'], test_size=0.15, random_state=42)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I randomized the training and testing data for better predictions. This is very important since the data has homogenous flairs for every 150 entries. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building our classifiers\n",
    "\n",
    "I will be building functions for different clasifiers. These functions will have a pipeline implemented for each model. This pipeline will first create an instance of the Count Vectorizer to create vectors of word counts and then it will also implement a TFID Transformer. \n",
    "\n",
    "**WRITE MORE HERE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 6503)\t1\n",
      "  (0, 4353)\t1\n",
      "  (0, 12864)\t1\n",
      "  (0, 5763)\t1\n",
      "  (0, 6553)\t1\n",
      "  (0, 3866)\t1\n",
      "  (0, 13979)\t1\n",
      "  (0, 673)\t1\n",
      "  (0, 12997)\t1\n",
      "  (1, 16669)\t3\n",
      "  (1, 7822)\t9\n",
      "  (1, 1259)\t10\n",
      "  (1, 9106)\t11\n",
      "  (1, 1220)\t1\n",
      "  (1, 322)\t1\n",
      "  (1, 13310)\t6\n",
      "  (1, 15414)\t4\n",
      "  (1, 13568)\t16\n",
      "  (1, 9227)\t1\n",
      "  (1, 14917)\t3\n",
      "  (1, 10981)\t2\n",
      "  (1, 1043)\t1\n",
      "  (1, 1843)\t1\n",
      "  (1, 11089)\t1\n",
      "  (1, 12052)\t4\n",
      "  :\t:\n",
      "  (1399, 6466)\t1\n",
      "  (1399, 12626)\t1\n",
      "  (1399, 14138)\t1\n",
      "  (1400, 7238)\t2\n",
      "  (1400, 14034)\t1\n",
      "  (1400, 15327)\t1\n",
      "  (1400, 5153)\t1\n",
      "  (1400, 2201)\t1\n",
      "  (1400, 6007)\t2\n",
      "  (1400, 13867)\t1\n",
      "  (1400, 1363)\t1\n",
      "  (1400, 570)\t4\n",
      "  (1400, 13215)\t1\n",
      "  (1400, 10563)\t1\n",
      "  (1400, 1443)\t1\n",
      "  (1400, 13709)\t4\n",
      "  (1400, 7880)\t1\n",
      "  (1401, 3799)\t1\n",
      "  (1401, 12679)\t1\n",
      "  (1401, 3316)\t1\n",
      "  (1401, 7300)\t1\n",
      "  (1401, 5849)\t1\n",
      "  (1401, 12471)\t1\n",
      "  (1401, 6067)\t1\n",
      "  (1401, 3773)\t1\n"
     ]
    }
   ],
   "source": [
    "# Creating an instance of the TFID transformer\n",
    "count_vec = CountVectorizer()\n",
    "X_train_counts = count_vec.fit_transform(X_train)\n",
    "print(X_train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 13979)\t0.3013721880655323\n",
      "  (0, 12997)\t0.3051264927290089\n",
      "  (0, 12864)\t0.35123291271193524\n",
      "  (0, 6553)\t0.2537328263091896\n",
      "  (0, 6503)\t0.3732966348536559\n",
      "  (0, 5763)\t0.4110148169841684\n",
      "  (0, 4353)\t0.3889510948424478\n",
      "  (0, 3866)\t0.33557845272314335\n",
      "  (0, 673)\t0.2369563506043619\n",
      "  (1, 16693)\t0.013605063330183872\n",
      "  (1, 16669)\t0.03109231737890458\n",
      "  (1, 16626)\t0.021906120263269963\n",
      "  (1, 16611)\t0.019895830123547936\n",
      "  (1, 16601)\t0.021906120263269963\n",
      "  (1, 16562)\t0.019248661248696376\n",
      "  (1, 16555)\t0.08762448105307985\n",
      "  (1, 16528)\t0.01587524984410388\n",
      "  (1, 16494)\t0.008904356598326654\n",
      "  (1, 16490)\t0.01569942415674625\n",
      "  (1, 16483)\t0.017543941428934177\n",
      "  (1, 16468)\t0.010474604323949428\n",
      "  (1, 16453)\t0.012513189669717345\n",
      "  (1, 16448)\t0.044468215218926674\n",
      "  (1, 16440)\t0.01508657799745058\n",
      "  (1, 16421)\t0.04106740205107267\n",
      "  :\t:\n",
      "  (1399, 337)\t0.04108675028835383\n",
      "  (1399, 152)\t0.028853470309070536\n",
      "  (1399, 45)\t0.026536652130275482\n",
      "  (1400, 15327)\t0.10179062806331833\n",
      "  (1400, 14034)\t0.09958411919214168\n",
      "  (1400, 13867)\t0.14022840445050938\n",
      "  (1400, 13709)\t0.6745322917802852\n",
      "  (1400, 13215)\t0.12387536407368088\n",
      "  (1400, 10563)\t0.13592699219141427\n",
      "  (1400, 7880)\t0.17819898833829492\n",
      "  (1400, 7238)\t0.10511733539278727\n",
      "  (1400, 6007)\t0.13981661511454824\n",
      "  (1400, 5153)\t0.10273445193013094\n",
      "  (1400, 2201)\t0.1081196328222901\n",
      "  (1400, 1443)\t0.1454929075846379\n",
      "  (1400, 1363)\t0.10936162748578805\n",
      "  (1400, 570)\t0.5945729612905087\n",
      "  (1401, 12679)\t0.3899583882750336\n",
      "  (1401, 12471)\t0.3617604646900273\n",
      "  (1401, 7300)\t0.2800465412904821\n",
      "  (1401, 6067)\t0.3617604646900273\n",
      "  (1401, 5849)\t0.34428289411055335\n",
      "  (1401, 3799)\t0.25463077416202795\n",
      "  (1401, 3773)\t0.497088078803033\n",
      "  (1401, 3316)\t0.27803061357358605\n"
     ]
    }
   ],
   "source": [
    "# Creating an instance of the TFID transformer\n",
    "tfidf_trans = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_trans.fit_transform(X_train_counts)\n",
    "print(X_train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model input Sequences\n",
    "pre_train = Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Classifier Pipeline\n",
    "The first one that I am building is the Naive Bayes Classifier. The one most suitable for word counts is the multinomial variant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nb_classifier(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    nb_fit = Pipeline([('vect', CountVectorizer()),\n",
    "                  ('tfidf', TfidfTransformer()),\n",
    "                  ('model', MultinomialNB()),\n",
    "                 ])\n",
    "    nb_fit.fit(X_train, y_train)    # Fitting the data to the trianing data\n",
    "    \n",
    "    # Making Predictions on the test data\n",
    "    y_pred = nb_fit.predict(X_test)\n",
    "    acc = accuracy_score(y_pred=y_pred, y_true=y_test)\n",
    "    print(\"Model Accuracy: {}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_reg(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    logreg = Pipeline([('vect', CountVectorizer()),\n",
    "                  ('tfidf', TfidfTransformer()),\n",
    "                  ('model', LogisticRegression(n_jobs=1, C=1e5)),\n",
    "                 ])\n",
    "    logreg.fit(X_train, y_train)     # Fitting the data to the trianing data\n",
    "\n",
    "    # Making Predictions on the test data\n",
    "    y_pred = logreg.predict(X_test)\n",
    "    acc = accuracy_score(y_pred=y_pred, y_true=y_test)\n",
    "    print(\"Model Accuracy: {}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    forest = Pipeline([('vect', CountVectorizer()),\n",
    "                  ('tfidf', TfidfTransformer()),\n",
    "                  ('model', RandomForestClassifier()),\n",
    "                 ])\n",
    "    forest.fit(X_train, y_train)    # Fitting the data to the trianing data\n",
    "    \n",
    "    # Making Predictions on the test data\n",
    "    y_pred = forest.predict(X_test)\n",
    "    acc = accuracy_score(y_pred=y_pred, y_true=y_test)\n",
    "    print(\"Model Accuracy: {}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svc(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    forest = Pipeline([('vect', CountVectorizer()),\n",
    "                  ('tfidf', TfidfTransformer()),\n",
    "                  ('model', SVC()),\n",
    "                 ])\n",
    "    forest.fit(X_train, y_train)    # Fitting the data to the trianing data\n",
    "    \n",
    "    # Making Predictions on the test data\n",
    "    y_pred = forest.predict(X_test)\n",
    "    acc = accuracy_score(y_pred=y_pred, y_true=y_test)\n",
    "    print(\"Model Accuracy: {}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_counts = count_vec.transform(X_test)\n",
    "X_test_tfidf = tfidf_trans.transform(X_test_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5564516129032258"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_model = SVC()\n",
    "log_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "y_pred = log_model.predict(X_test_tfidf)\n",
    "accuracy_score(y_pred=y_pred, y_true=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate Naive Bayes Classifier\n",
      "Model Accuracy: 0.532258064516129\n",
      "Evaluate Random Forest Classifier\n",
      "Model Accuracy: 0.47580645161290325\n",
      "Evaluate Logistic Regression Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prakhar/.local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.5766129032258065\n",
      "Evaluate SVC Model\n",
      "Model Accuracy: 0.5564516129032258\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluate Naive Bayes Classifier\")\n",
    "nb_classifier(X_train, X_test, y_train, y_test)\n",
    "\n",
    "print(\"Evaluate Random Forest Classifier\")\n",
    "random_forest(X_train, X_test, y_train, y_test)\n",
    "\n",
    "print(\"Evaluate Logistic Regression Model\")\n",
    "log_reg(X_train, X_test, y_train, y_test)\n",
    "\n",
    "print(\"Evaluate SVC Model\")\n",
    "svc(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression Model gives the best results and was working well in the flask app. Apart from that the model is not converging for some cases. However, Heroku results in a error that says that module is not found even though it is present there so I will be using SVC right now. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC Model Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n",
      "[CV] C=0.1, gamma=1, kernel=linear ...................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....... C=0.1, gamma=1, kernel=linear, score=0.096, total=   1.0s\n",
      "[CV] C=0.1, gamma=1, kernel=linear ...................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....... C=0.1, gamma=1, kernel=linear, score=0.096, total=   1.0s\n",
      "[CV] C=0.1, gamma=1, kernel=linear ...................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    1.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....... C=0.1, gamma=1, kernel=linear, score=0.104, total=   1.0s\n",
      "[CV] C=0.1, gamma=1, kernel=linear ...................................\n",
      "[CV] ....... C=0.1, gamma=1, kernel=linear, score=0.096, total=   1.0s\n",
      "[CV] C=0.1, gamma=1, kernel=linear ...................................\n",
      "[CV] ....... C=0.1, gamma=1, kernel=linear, score=0.096, total=   1.0s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.096, total=   1.0s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.096, total=   1.1s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.100, total=   1.1s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.096, total=   1.1s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.096, total=   1.1s\n",
      "[CV] C=0.1, gamma=1, kernel=poly .....................................\n",
      "[CV] ......... C=0.1, gamma=1, kernel=poly, score=0.096, total=   1.1s\n",
      "[CV] C=0.1, gamma=1, kernel=poly .....................................\n",
      "[CV] ......... C=0.1, gamma=1, kernel=poly, score=0.096, total=   1.1s\n",
      "[CV] C=0.1, gamma=1, kernel=poly .....................................\n",
      "[CV] ......... C=0.1, gamma=1, kernel=poly, score=0.100, total=   1.1s\n",
      "[CV] C=0.1, gamma=1, kernel=poly .....................................\n",
      "[CV] ......... C=0.1, gamma=1, kernel=poly, score=0.096, total=   1.0s\n",
      "[CV] C=0.1, gamma=1, kernel=poly .....................................\n",
      "[CV] ......... C=0.1, gamma=1, kernel=poly, score=0.096, total=   1.2s\n",
      "[CV] C=0.1, gamma=1, kernel=sigmoid ..................................\n",
      "[CV] ...... C=0.1, gamma=1, kernel=sigmoid, score=0.096, total=   1.0s\n",
      "[CV] C=0.1, gamma=1, kernel=sigmoid ..................................\n",
      "[CV] ...... C=0.1, gamma=1, kernel=sigmoid, score=0.096, total=   1.1s\n",
      "[CV] C=0.1, gamma=1, kernel=sigmoid ..................................\n",
      "[CV] ...... C=0.1, gamma=1, kernel=sigmoid, score=0.100, total=   1.0s\n",
      "[CV] C=0.1, gamma=1, kernel=sigmoid ..................................\n",
      "[CV] ...... C=0.1, gamma=1, kernel=sigmoid, score=0.096, total=   1.1s\n",
      "[CV] C=0.1, gamma=1, kernel=sigmoid ..................................\n",
      "[CV] ...... C=0.1, gamma=1, kernel=sigmoid, score=0.096, total=   1.2s\n",
      "[CV] C=0.1, gamma=0.1, kernel=linear .................................\n",
      "[CV] ..... C=0.1, gamma=0.1, kernel=linear, score=0.096, total=   1.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=linear .................................\n",
      "[CV] ..... C=0.1, gamma=0.1, kernel=linear, score=0.096, total=   1.3s\n",
      "[CV] C=0.1, gamma=0.1, kernel=linear .................................\n",
      "[CV] ..... C=0.1, gamma=0.1, kernel=linear, score=0.104, total=   1.3s\n",
      "[CV] C=0.1, gamma=0.1, kernel=linear .................................\n",
      "[CV] ..... C=0.1, gamma=0.1, kernel=linear, score=0.096, total=   1.2s\n",
      "[CV] C=0.1, gamma=0.1, kernel=linear .................................\n",
      "[CV] ..... C=0.1, gamma=0.1, kernel=linear, score=0.096, total=   1.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.096, total=   1.1s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.096, total=   1.2s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.100, total=   1.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.096, total=   1.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.096, total=   1.1s\n",
      "[CV] C=0.1, gamma=0.1, kernel=poly ...................................\n",
      "[CV] ....... C=0.1, gamma=0.1, kernel=poly, score=0.096, total=   1.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=poly ...................................\n",
      "[CV] ....... C=0.1, gamma=0.1, kernel=poly, score=0.096, total=   1.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=poly ...................................\n",
      "[CV] ....... C=0.1, gamma=0.1, kernel=poly, score=0.100, total=   1.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=poly ...................................\n",
      "[CV] ....... C=0.1, gamma=0.1, kernel=poly, score=0.096, total=   1.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=poly ...................................\n",
      "[CV] ....... C=0.1, gamma=0.1, kernel=poly, score=0.096, total=   1.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=sigmoid ................................\n",
      "[CV] .... C=0.1, gamma=0.1, kernel=sigmoid, score=0.096, total=   1.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=sigmoid ................................\n",
      "[CV] .... C=0.1, gamma=0.1, kernel=sigmoid, score=0.096, total=   1.1s\n",
      "[CV] C=0.1, gamma=0.1, kernel=sigmoid ................................\n",
      "[CV] .... C=0.1, gamma=0.1, kernel=sigmoid, score=0.100, total=   1.1s\n",
      "[CV] C=0.1, gamma=0.1, kernel=sigmoid ................................\n",
      "[CV] .... C=0.1, gamma=0.1, kernel=sigmoid, score=0.096, total=   1.1s\n",
      "[CV] C=0.1, gamma=0.1, kernel=sigmoid ................................\n",
      "[CV] .... C=0.1, gamma=0.1, kernel=sigmoid, score=0.096, total=   1.0s\n",
      "[CV] C=0.1, gamma=0.01, kernel=linear ................................\n",
      "[CV] .... C=0.1, gamma=0.01, kernel=linear, score=0.096, total=   0.9s\n",
      "[CV] C=0.1, gamma=0.01, kernel=linear ................................\n",
      "[CV] .... C=0.1, gamma=0.01, kernel=linear, score=0.096, total=   1.0s\n",
      "[CV] C=0.1, gamma=0.01, kernel=linear ................................\n",
      "[CV] .... C=0.1, gamma=0.01, kernel=linear, score=0.104, total=   1.1s\n",
      "[CV] C=0.1, gamma=0.01, kernel=linear ................................\n",
      "[CV] .... C=0.1, gamma=0.01, kernel=linear, score=0.096, total=   1.1s\n",
      "[CV] C=0.1, gamma=0.01, kernel=linear ................................\n",
      "[CV] .... C=0.1, gamma=0.01, kernel=linear, score=0.096, total=   1.1s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.096, total=   1.2s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.096, total=   1.2s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.100, total=   1.1s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.096, total=   1.2s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.096, total=   1.1s\n",
      "[CV] C=0.1, gamma=0.01, kernel=poly ..................................\n",
      "[CV] ...... C=0.1, gamma=0.01, kernel=poly, score=0.096, total=   1.1s\n",
      "[CV] C=0.1, gamma=0.01, kernel=poly ..................................\n",
      "[CV] ...... C=0.1, gamma=0.01, kernel=poly, score=0.096, total=   1.1s\n",
      "[CV] C=0.1, gamma=0.01, kernel=poly ..................................\n",
      "[CV] ...... C=0.1, gamma=0.01, kernel=poly, score=0.100, total=   1.1s\n",
      "[CV] C=0.1, gamma=0.01, kernel=poly ..................................\n",
      "[CV] ...... C=0.1, gamma=0.01, kernel=poly, score=0.096, total=   1.1s\n",
      "[CV] C=0.1, gamma=0.01, kernel=poly ..................................\n",
      "[CV] ...... C=0.1, gamma=0.01, kernel=poly, score=0.096, total=   1.0s\n",
      "[CV] C=0.1, gamma=0.01, kernel=sigmoid ...............................\n",
      "[CV] ... C=0.1, gamma=0.01, kernel=sigmoid, score=0.096, total=   1.0s\n",
      "[CV] C=0.1, gamma=0.01, kernel=sigmoid ...............................\n",
      "[CV] ... C=0.1, gamma=0.01, kernel=sigmoid, score=0.096, total=   1.1s\n",
      "[CV] C=0.1, gamma=0.01, kernel=sigmoid ...............................\n",
      "[CV] ... C=0.1, gamma=0.01, kernel=sigmoid, score=0.100, total=   1.1s\n",
      "[CV] C=0.1, gamma=0.01, kernel=sigmoid ...............................\n",
      "[CV] ... C=0.1, gamma=0.01, kernel=sigmoid, score=0.096, total=   1.1s\n",
      "[CV] C=0.1, gamma=0.01, kernel=sigmoid ...............................\n",
      "[CV] ... C=0.1, gamma=0.01, kernel=sigmoid, score=0.096, total=   1.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=linear ...............................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... C=0.1, gamma=0.001, kernel=linear, score=0.096, total=   1.1s\n",
      "[CV] C=0.1, gamma=0.001, kernel=linear ...............................\n",
      "[CV] ... C=0.1, gamma=0.001, kernel=linear, score=0.096, total=   1.2s\n",
      "[CV] C=0.1, gamma=0.001, kernel=linear ...............................\n",
      "[CV] ... C=0.1, gamma=0.001, kernel=linear, score=0.104, total=   1.1s\n",
      "[CV] C=0.1, gamma=0.001, kernel=linear ...............................\n",
      "[CV] ... C=0.1, gamma=0.001, kernel=linear, score=0.096, total=   1.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=linear ...............................\n",
      "[CV] ... C=0.1, gamma=0.001, kernel=linear, score=0.096, total=   1.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.096, total=   1.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.096, total=   1.2s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.100, total=   1.2s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.096, total=   1.1s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.096, total=   1.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=poly .................................\n",
      "[CV] ..... C=0.1, gamma=0.001, kernel=poly, score=0.096, total=   0.9s\n",
      "[CV] C=0.1, gamma=0.001, kernel=poly .................................\n",
      "[CV] ..... C=0.1, gamma=0.001, kernel=poly, score=0.096, total=   1.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=poly .................................\n",
      "[CV] ..... C=0.1, gamma=0.001, kernel=poly, score=0.100, total=   1.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=poly .................................\n",
      "[CV] ..... C=0.1, gamma=0.001, kernel=poly, score=0.096, total=   1.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=poly .................................\n",
      "[CV] ..... C=0.1, gamma=0.001, kernel=poly, score=0.096, total=   1.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=sigmoid ..............................\n",
      "[CV] .. C=0.1, gamma=0.001, kernel=sigmoid, score=0.096, total=   1.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=sigmoid ..............................\n",
      "[CV] .. C=0.1, gamma=0.001, kernel=sigmoid, score=0.096, total=   1.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=sigmoid ..............................\n",
      "[CV] .. C=0.1, gamma=0.001, kernel=sigmoid, score=0.100, total=   1.2s\n",
      "[CV] C=0.1, gamma=0.001, kernel=sigmoid ..............................\n",
      "[CV] .. C=0.1, gamma=0.001, kernel=sigmoid, score=0.096, total=   1.1s\n",
      "[CV] C=0.1, gamma=0.001, kernel=sigmoid ..............................\n",
      "[CV] .. C=0.1, gamma=0.001, kernel=sigmoid, score=0.096, total=   1.1s\n",
      "[CV] C=1, gamma=1, kernel=linear .....................................\n",
      "[CV] ......... C=1, gamma=1, kernel=linear, score=0.566, total=   1.1s\n",
      "[CV] C=1, gamma=1, kernel=linear .....................................\n",
      "[CV] ......... C=1, gamma=1, kernel=linear, score=0.562, total=   1.2s\n",
      "[CV] C=1, gamma=1, kernel=linear .....................................\n",
      "[CV] ......... C=1, gamma=1, kernel=linear, score=0.571, total=   1.0s\n",
      "[CV] C=1, gamma=1, kernel=linear .....................................\n",
      "[CV] ......... C=1, gamma=1, kernel=linear, score=0.550, total=   1.0s\n",
      "[CV] C=1, gamma=1, kernel=linear .....................................\n",
      "[CV] ......... C=1, gamma=1, kernel=linear, score=0.550, total=   1.0s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.541, total=   1.1s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.470, total=   1.1s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.525, total=   1.0s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.482, total=   1.0s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.514, total=   1.0s\n",
      "[CV] C=1, gamma=1, kernel=poly .......................................\n",
      "[CV] ........... C=1, gamma=1, kernel=poly, score=0.153, total=   1.0s\n",
      "[CV] C=1, gamma=1, kernel=poly .......................................\n",
      "[CV] ........... C=1, gamma=1, kernel=poly, score=0.160, total=   1.3s\n",
      "[CV] C=1, gamma=1, kernel=poly .......................................\n",
      "[CV] ........... C=1, gamma=1, kernel=poly, score=0.161, total=   1.2s\n",
      "[CV] C=1, gamma=1, kernel=poly .......................................\n",
      "[CV] ........... C=1, gamma=1, kernel=poly, score=0.136, total=   1.5s\n",
      "[CV] C=1, gamma=1, kernel=poly .......................................\n",
      "[CV] ........... C=1, gamma=1, kernel=poly, score=0.161, total=   1.0s\n",
      "[CV] C=1, gamma=1, kernel=sigmoid ....................................\n",
      "[CV] ........ C=1, gamma=1, kernel=sigmoid, score=0.569, total=   1.0s\n",
      "[CV] C=1, gamma=1, kernel=sigmoid ....................................\n",
      "[CV] ........ C=1, gamma=1, kernel=sigmoid, score=0.537, total=   1.0s\n",
      "[CV] C=1, gamma=1, kernel=sigmoid ....................................\n",
      "[CV] ........ C=1, gamma=1, kernel=sigmoid, score=0.561, total=   1.0s\n",
      "[CV] C=1, gamma=1, kernel=sigmoid ....................................\n",
      "[CV] ........ C=1, gamma=1, kernel=sigmoid, score=0.529, total=   1.0s\n",
      "[CV] C=1, gamma=1, kernel=sigmoid ....................................\n",
      "[CV] ........ C=1, gamma=1, kernel=sigmoid, score=0.554, total=   1.0s\n",
      "[CV] C=1, gamma=0.1, kernel=linear ...................................\n",
      "[CV] ....... C=1, gamma=0.1, kernel=linear, score=0.566, total=   0.9s\n",
      "[CV] C=1, gamma=0.1, kernel=linear ...................................\n",
      "[CV] ....... C=1, gamma=0.1, kernel=linear, score=0.562, total=   1.0s\n",
      "[CV] C=1, gamma=0.1, kernel=linear ...................................\n",
      "[CV] ....... C=1, gamma=0.1, kernel=linear, score=0.571, total=   1.0s\n",
      "[CV] C=1, gamma=0.1, kernel=linear ...................................\n",
      "[CV] ....... C=1, gamma=0.1, kernel=linear, score=0.550, total=   1.0s\n",
      "[CV] C=1, gamma=0.1, kernel=linear ...................................\n",
      "[CV] ....... C=1, gamma=0.1, kernel=linear, score=0.550, total=   1.0s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.135, total=   1.0s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.139, total=   1.0s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.139, total=   1.0s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.114, total=   1.0s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.143, total=   1.1s\n",
      "[CV] C=1, gamma=0.1, kernel=poly .....................................\n",
      "[CV] ......... C=1, gamma=0.1, kernel=poly, score=0.096, total=   0.9s\n",
      "[CV] C=1, gamma=0.1, kernel=poly .....................................\n",
      "[CV] ......... C=1, gamma=0.1, kernel=poly, score=0.096, total=   1.0s\n",
      "[CV] C=1, gamma=0.1, kernel=poly .....................................\n",
      "[CV] ......... C=1, gamma=0.1, kernel=poly, score=0.100, total=   1.0s\n",
      "[CV] C=1, gamma=0.1, kernel=poly .....................................\n",
      "[CV] ......... C=1, gamma=0.1, kernel=poly, score=0.096, total=   1.0s\n",
      "[CV] C=1, gamma=0.1, kernel=poly .....................................\n",
      "[CV] ......... C=1, gamma=0.1, kernel=poly, score=0.096, total=   1.0s\n",
      "[CV] C=1, gamma=0.1, kernel=sigmoid ..................................\n",
      "[CV] ...... C=1, gamma=0.1, kernel=sigmoid, score=0.096, total=   1.0s\n",
      "[CV] C=1, gamma=0.1, kernel=sigmoid ..................................\n",
      "[CV] ...... C=1, gamma=0.1, kernel=sigmoid, score=0.096, total=   1.0s\n",
      "[CV] C=1, gamma=0.1, kernel=sigmoid ..................................\n",
      "[CV] ...... C=1, gamma=0.1, kernel=sigmoid, score=0.104, total=   1.0s\n",
      "[CV] C=1, gamma=0.1, kernel=sigmoid ..................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...... C=1, gamma=0.1, kernel=sigmoid, score=0.096, total=   1.0s\n",
      "[CV] C=1, gamma=0.1, kernel=sigmoid ..................................\n",
      "[CV] ...... C=1, gamma=0.1, kernel=sigmoid, score=0.096, total=   1.0s\n",
      "[CV] C=1, gamma=0.01, kernel=linear ..................................\n",
      "[CV] ...... C=1, gamma=0.01, kernel=linear, score=0.566, total=   0.9s\n",
      "[CV] C=1, gamma=0.01, kernel=linear ..................................\n",
      "[CV] ...... C=1, gamma=0.01, kernel=linear, score=0.562, total=   1.0s\n",
      "[CV] C=1, gamma=0.01, kernel=linear ..................................\n",
      "[CV] ...... C=1, gamma=0.01, kernel=linear, score=0.571, total=   1.0s\n",
      "[CV] C=1, gamma=0.01, kernel=linear ..................................\n",
      "[CV] ...... C=1, gamma=0.01, kernel=linear, score=0.550, total=   1.0s\n",
      "[CV] C=1, gamma=0.01, kernel=linear ..................................\n",
      "[CV] ...... C=1, gamma=0.01, kernel=linear, score=0.550, total=   1.0s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.096, total=   1.0s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.096, total=   1.0s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.100, total=   1.0s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.096, total=   1.0s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.096, total=   1.0s\n",
      "[CV] C=1, gamma=0.01, kernel=poly ....................................\n",
      "[CV] ........ C=1, gamma=0.01, kernel=poly, score=0.096, total=   0.9s\n",
      "[CV] C=1, gamma=0.01, kernel=poly ....................................\n",
      "[CV] ........ C=1, gamma=0.01, kernel=poly, score=0.096, total=   1.0s\n",
      "[CV] C=1, gamma=0.01, kernel=poly ....................................\n",
      "[CV] ........ C=1, gamma=0.01, kernel=poly, score=0.100, total=   1.0s\n",
      "[CV] C=1, gamma=0.01, kernel=poly ....................................\n",
      "[CV] ........ C=1, gamma=0.01, kernel=poly, score=0.096, total=   1.0s\n",
      "[CV] C=1, gamma=0.01, kernel=poly ....................................\n",
      "[CV] ........ C=1, gamma=0.01, kernel=poly, score=0.096, total=   1.0s\n",
      "[CV] C=1, gamma=0.01, kernel=sigmoid .................................\n",
      "[CV] ..... C=1, gamma=0.01, kernel=sigmoid, score=0.096, total=   0.9s\n",
      "[CV] C=1, gamma=0.01, kernel=sigmoid .................................\n",
      "[CV] ..... C=1, gamma=0.01, kernel=sigmoid, score=0.096, total=   1.0s\n",
      "[CV] C=1, gamma=0.01, kernel=sigmoid .................................\n",
      "[CV] ..... C=1, gamma=0.01, kernel=sigmoid, score=0.100, total=   1.0s\n",
      "[CV] C=1, gamma=0.01, kernel=sigmoid .................................\n",
      "[CV] ..... C=1, gamma=0.01, kernel=sigmoid, score=0.096, total=   1.0s\n",
      "[CV] C=1, gamma=0.01, kernel=sigmoid .................................\n",
      "[CV] ..... C=1, gamma=0.01, kernel=sigmoid, score=0.096, total=   1.0s\n",
      "[CV] C=1, gamma=0.001, kernel=linear .................................\n",
      "[CV] ..... C=1, gamma=0.001, kernel=linear, score=0.566, total=   0.9s\n",
      "[CV] C=1, gamma=0.001, kernel=linear .................................\n",
      "[CV] ..... C=1, gamma=0.001, kernel=linear, score=0.562, total=   1.0s\n",
      "[CV] C=1, gamma=0.001, kernel=linear .................................\n",
      "[CV] ..... C=1, gamma=0.001, kernel=linear, score=0.571, total=   1.0s\n",
      "[CV] C=1, gamma=0.001, kernel=linear .................................\n",
      "[CV] ..... C=1, gamma=0.001, kernel=linear, score=0.550, total=   1.0s\n",
      "[CV] C=1, gamma=0.001, kernel=linear .................................\n",
      "[CV] ..... C=1, gamma=0.001, kernel=linear, score=0.550, total=   1.0s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.096, total=   1.0s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.096, total=   1.1s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.100, total=   1.0s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.096, total=   1.0s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.096, total=   1.0s\n",
      "[CV] C=1, gamma=0.001, kernel=poly ...................................\n",
      "[CV] ....... C=1, gamma=0.001, kernel=poly, score=0.096, total=   0.9s\n",
      "[CV] C=1, gamma=0.001, kernel=poly ...................................\n",
      "[CV] ....... C=1, gamma=0.001, kernel=poly, score=0.096, total=   1.0s\n",
      "[CV] C=1, gamma=0.001, kernel=poly ...................................\n",
      "[CV] ....... C=1, gamma=0.001, kernel=poly, score=0.100, total=   1.0s\n",
      "[CV] C=1, gamma=0.001, kernel=poly ...................................\n",
      "[CV] ....... C=1, gamma=0.001, kernel=poly, score=0.096, total=   0.9s\n",
      "[CV] C=1, gamma=0.001, kernel=poly ...................................\n",
      "[CV] ....... C=1, gamma=0.001, kernel=poly, score=0.096, total=   0.9s\n",
      "[CV] C=1, gamma=0.001, kernel=sigmoid ................................\n",
      "[CV] .... C=1, gamma=0.001, kernel=sigmoid, score=0.096, total=   0.9s\n",
      "[CV] C=1, gamma=0.001, kernel=sigmoid ................................\n",
      "[CV] .... C=1, gamma=0.001, kernel=sigmoid, score=0.096, total=   0.9s\n",
      "[CV] C=1, gamma=0.001, kernel=sigmoid ................................\n",
      "[CV] .... C=1, gamma=0.001, kernel=sigmoid, score=0.100, total=   0.9s\n",
      "[CV] C=1, gamma=0.001, kernel=sigmoid ................................\n",
      "[CV] .... C=1, gamma=0.001, kernel=sigmoid, score=0.096, total=   1.0s\n",
      "[CV] C=1, gamma=0.001, kernel=sigmoid ................................\n",
      "[CV] .... C=1, gamma=0.001, kernel=sigmoid, score=0.096, total=   0.9s\n",
      "[CV] C=10, gamma=1, kernel=linear ....................................\n",
      "[CV] ........ C=10, gamma=1, kernel=linear, score=0.559, total=   0.9s\n",
      "[CV] C=10, gamma=1, kernel=linear ....................................\n",
      "[CV] ........ C=10, gamma=1, kernel=linear, score=0.555, total=   1.0s\n",
      "[CV] C=10, gamma=1, kernel=linear ....................................\n",
      "[CV] ........ C=10, gamma=1, kernel=linear, score=0.561, total=   0.9s\n",
      "[CV] C=10, gamma=1, kernel=linear ....................................\n",
      "[CV] ........ C=10, gamma=1, kernel=linear, score=0.543, total=   0.9s\n",
      "[CV] C=10, gamma=1, kernel=linear ....................................\n",
      "[CV] ........ C=10, gamma=1, kernel=linear, score=0.550, total=   0.9s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.573, total=   1.0s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.530, total=   1.0s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.561, total=   1.0s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.536, total=   1.0s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.550, total=   1.0s\n",
      "[CV] C=10, gamma=1, kernel=poly ......................................\n",
      "[CV] .......... C=10, gamma=1, kernel=poly, score=0.189, total=   0.9s\n",
      "[CV] C=10, gamma=1, kernel=poly ......................................\n",
      "[CV] .......... C=10, gamma=1, kernel=poly, score=0.185, total=   0.9s\n",
      "[CV] C=10, gamma=1, kernel=poly ......................................\n",
      "[CV] .......... C=10, gamma=1, kernel=poly, score=0.196, total=   0.9s\n",
      "[CV] C=10, gamma=1, kernel=poly ......................................\n",
      "[CV] .......... C=10, gamma=1, kernel=poly, score=0.179, total=   1.0s\n",
      "[CV] C=10, gamma=1, kernel=poly ......................................\n",
      "[CV] .......... C=10, gamma=1, kernel=poly, score=0.204, total=   0.9s\n",
      "[CV] C=10, gamma=1, kernel=sigmoid ...................................\n",
      "[CV] ....... C=10, gamma=1, kernel=sigmoid, score=0.548, total=   0.9s\n",
      "[CV] C=10, gamma=1, kernel=sigmoid ...................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....... C=10, gamma=1, kernel=sigmoid, score=0.559, total=   0.9s\n",
      "[CV] C=10, gamma=1, kernel=sigmoid ...................................\n",
      "[CV] ....... C=10, gamma=1, kernel=sigmoid, score=0.557, total=   0.9s\n",
      "[CV] C=10, gamma=1, kernel=sigmoid ...................................\n",
      "[CV] ....... C=10, gamma=1, kernel=sigmoid, score=0.539, total=   0.9s\n",
      "[CV] C=10, gamma=1, kernel=sigmoid ...................................\n",
      "[CV] ....... C=10, gamma=1, kernel=sigmoid, score=0.546, total=   0.9s\n",
      "[CV] C=10, gamma=0.1, kernel=linear ..................................\n",
      "[CV] ...... C=10, gamma=0.1, kernel=linear, score=0.559, total=   0.9s\n",
      "[CV] C=10, gamma=0.1, kernel=linear ..................................\n",
      "[CV] ...... C=10, gamma=0.1, kernel=linear, score=0.555, total=   0.9s\n",
      "[CV] C=10, gamma=0.1, kernel=linear ..................................\n",
      "[CV] ...... C=10, gamma=0.1, kernel=linear, score=0.561, total=   0.9s\n",
      "[CV] C=10, gamma=0.1, kernel=linear ..................................\n",
      "[CV] ...... C=10, gamma=0.1, kernel=linear, score=0.543, total=   0.9s\n",
      "[CV] C=10, gamma=0.1, kernel=linear ..................................\n",
      "[CV] ...... C=10, gamma=0.1, kernel=linear, score=0.550, total=   0.9s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.566, total=   1.0s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.555, total=   1.0s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.561, total=   1.0s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.539, total=   1.0s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.546, total=   1.0s\n",
      "[CV] C=10, gamma=0.1, kernel=poly ....................................\n",
      "[CV] ........ C=10, gamma=0.1, kernel=poly, score=0.096, total=   0.9s\n",
      "[CV] C=10, gamma=0.1, kernel=poly ....................................\n",
      "[CV] ........ C=10, gamma=0.1, kernel=poly, score=0.096, total=   0.9s\n",
      "[CV] C=10, gamma=0.1, kernel=poly ....................................\n",
      "[CV] ........ C=10, gamma=0.1, kernel=poly, score=0.100, total=   0.9s\n",
      "[CV] C=10, gamma=0.1, kernel=poly ....................................\n",
      "[CV] ........ C=10, gamma=0.1, kernel=poly, score=0.096, total=   0.9s\n",
      "[CV] C=10, gamma=0.1, kernel=poly ....................................\n",
      "[CV] ........ C=10, gamma=0.1, kernel=poly, score=0.096, total=   1.0s\n",
      "[CV] C=10, gamma=0.1, kernel=sigmoid .................................\n",
      "[CV] ..... C=10, gamma=0.1, kernel=sigmoid, score=0.566, total=   0.9s\n",
      "[CV] C=10, gamma=0.1, kernel=sigmoid .................................\n",
      "[CV] ..... C=10, gamma=0.1, kernel=sigmoid, score=0.562, total=   0.9s\n",
      "[CV] C=10, gamma=0.1, kernel=sigmoid .................................\n",
      "[CV] ..... C=10, gamma=0.1, kernel=sigmoid, score=0.571, total=   1.0s\n",
      "[CV] C=10, gamma=0.1, kernel=sigmoid .................................\n",
      "[CV] ..... C=10, gamma=0.1, kernel=sigmoid, score=0.550, total=   0.9s\n",
      "[CV] C=10, gamma=0.1, kernel=sigmoid .................................\n",
      "[CV] ..... C=10, gamma=0.1, kernel=sigmoid, score=0.550, total=   0.9s\n",
      "[CV] C=10, gamma=0.01, kernel=linear .................................\n",
      "[CV] ..... C=10, gamma=0.01, kernel=linear, score=0.559, total=   0.9s\n",
      "[CV] C=10, gamma=0.01, kernel=linear .................................\n",
      "[CV] ..... C=10, gamma=0.01, kernel=linear, score=0.555, total=   0.9s\n",
      "[CV] C=10, gamma=0.01, kernel=linear .................................\n",
      "[CV] ..... C=10, gamma=0.01, kernel=linear, score=0.561, total=   0.9s\n",
      "[CV] C=10, gamma=0.01, kernel=linear .................................\n",
      "[CV] ..... C=10, gamma=0.01, kernel=linear, score=0.543, total=   0.9s\n",
      "[CV] C=10, gamma=0.01, kernel=linear .................................\n",
      "[CV] ..... C=10, gamma=0.01, kernel=linear, score=0.550, total=   0.9s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.149, total=   0.9s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.160, total=   1.0s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.150, total=   0.9s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.129, total=   0.9s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.168, total=   1.0s\n",
      "[CV] C=10, gamma=0.01, kernel=poly ...................................\n",
      "[CV] ....... C=10, gamma=0.01, kernel=poly, score=0.096, total=   0.9s\n",
      "[CV] C=10, gamma=0.01, kernel=poly ...................................\n",
      "[CV] ....... C=10, gamma=0.01, kernel=poly, score=0.096, total=   0.9s\n",
      "[CV] C=10, gamma=0.01, kernel=poly ...................................\n",
      "[CV] ....... C=10, gamma=0.01, kernel=poly, score=0.100, total=   0.9s\n",
      "[CV] C=10, gamma=0.01, kernel=poly ...................................\n",
      "[CV] ....... C=10, gamma=0.01, kernel=poly, score=0.096, total=   0.9s\n",
      "[CV] C=10, gamma=0.01, kernel=poly ...................................\n",
      "[CV] ....... C=10, gamma=0.01, kernel=poly, score=0.096, total=   0.9s\n",
      "[CV] C=10, gamma=0.01, kernel=sigmoid ................................\n",
      "[CV] .... C=10, gamma=0.01, kernel=sigmoid, score=0.096, total=   0.9s\n",
      "[CV] C=10, gamma=0.01, kernel=sigmoid ................................\n",
      "[CV] .... C=10, gamma=0.01, kernel=sigmoid, score=0.096, total=   0.9s\n",
      "[CV] C=10, gamma=0.01, kernel=sigmoid ................................\n",
      "[CV] .... C=10, gamma=0.01, kernel=sigmoid, score=0.104, total=   0.9s\n",
      "[CV] C=10, gamma=0.01, kernel=sigmoid ................................\n",
      "[CV] .... C=10, gamma=0.01, kernel=sigmoid, score=0.096, total=   1.0s\n",
      "[CV] C=10, gamma=0.01, kernel=sigmoid ................................\n",
      "[CV] .... C=10, gamma=0.01, kernel=sigmoid, score=0.096, total=   0.9s\n",
      "[CV] C=10, gamma=0.001, kernel=linear ................................\n",
      "[CV] .... C=10, gamma=0.001, kernel=linear, score=0.559, total=   0.9s\n",
      "[CV] C=10, gamma=0.001, kernel=linear ................................\n",
      "[CV] .... C=10, gamma=0.001, kernel=linear, score=0.555, total=   0.9s\n",
      "[CV] C=10, gamma=0.001, kernel=linear ................................\n",
      "[CV] .... C=10, gamma=0.001, kernel=linear, score=0.561, total=   1.0s\n",
      "[CV] C=10, gamma=0.001, kernel=linear ................................\n",
      "[CV] .... C=10, gamma=0.001, kernel=linear, score=0.543, total=   0.9s\n",
      "[CV] C=10, gamma=0.001, kernel=linear ................................\n",
      "[CV] .... C=10, gamma=0.001, kernel=linear, score=0.550, total=   0.9s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.096, total=   0.9s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.096, total=   0.9s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.100, total=   0.9s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.096, total=   0.9s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.096, total=   0.9s\n",
      "[CV] C=10, gamma=0.001, kernel=poly ..................................\n",
      "[CV] ...... C=10, gamma=0.001, kernel=poly, score=0.096, total=   0.9s\n",
      "[CV] C=10, gamma=0.001, kernel=poly ..................................\n",
      "[CV] ...... C=10, gamma=0.001, kernel=poly, score=0.096, total=   0.9s\n",
      "[CV] C=10, gamma=0.001, kernel=poly ..................................\n",
      "[CV] ...... C=10, gamma=0.001, kernel=poly, score=0.100, total=   0.9s\n",
      "[CV] C=10, gamma=0.001, kernel=poly ..................................\n",
      "[CV] ...... C=10, gamma=0.001, kernel=poly, score=0.096, total=   0.9s\n",
      "[CV] C=10, gamma=0.001, kernel=poly ..................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...... C=10, gamma=0.001, kernel=poly, score=0.096, total=   1.0s\n",
      "[CV] C=10, gamma=0.001, kernel=sigmoid ...............................\n",
      "[CV] ... C=10, gamma=0.001, kernel=sigmoid, score=0.096, total=   0.9s\n",
      "[CV] C=10, gamma=0.001, kernel=sigmoid ...............................\n",
      "[CV] ... C=10, gamma=0.001, kernel=sigmoid, score=0.096, total=   0.9s\n",
      "[CV] C=10, gamma=0.001, kernel=sigmoid ...............................\n",
      "[CV] ... C=10, gamma=0.001, kernel=sigmoid, score=0.100, total=   0.9s\n",
      "[CV] C=10, gamma=0.001, kernel=sigmoid ...............................\n",
      "[CV] ... C=10, gamma=0.001, kernel=sigmoid, score=0.096, total=   0.9s\n",
      "[CV] C=10, gamma=0.001, kernel=sigmoid ...............................\n",
      "[CV] ... C=10, gamma=0.001, kernel=sigmoid, score=0.096, total=   0.9s\n",
      "[CV] C=100, gamma=1, kernel=linear ...................................\n",
      "[CV] ....... C=100, gamma=1, kernel=linear, score=0.559, total=   0.9s\n",
      "[CV] C=100, gamma=1, kernel=linear ...................................\n",
      "[CV] ....... C=100, gamma=1, kernel=linear, score=0.555, total=   0.9s\n",
      "[CV] C=100, gamma=1, kernel=linear ...................................\n",
      "[CV] ....... C=100, gamma=1, kernel=linear, score=0.561, total=   0.9s\n",
      "[CV] C=100, gamma=1, kernel=linear ...................................\n",
      "[CV] ....... C=100, gamma=1, kernel=linear, score=0.543, total=   1.0s\n",
      "[CV] C=100, gamma=1, kernel=linear ...................................\n",
      "[CV] ....... C=100, gamma=1, kernel=linear, score=0.550, total=   0.9s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.573, total=   0.9s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.530, total=   1.1s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.561, total=   1.0s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.536, total=   1.0s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.550, total=   1.0s\n",
      "[CV] C=100, gamma=1, kernel=poly .....................................\n",
      "[CV] ......... C=100, gamma=1, kernel=poly, score=0.189, total=   0.9s\n",
      "[CV] C=100, gamma=1, kernel=poly .....................................\n",
      "[CV] ......... C=100, gamma=1, kernel=poly, score=0.185, total=   0.9s\n",
      "[CV] C=100, gamma=1, kernel=poly .....................................\n",
      "[CV] ......... C=100, gamma=1, kernel=poly, score=0.196, total=   0.9s\n",
      "[CV] C=100, gamma=1, kernel=poly .....................................\n",
      "[CV] ......... C=100, gamma=1, kernel=poly, score=0.179, total=   0.9s\n",
      "[CV] C=100, gamma=1, kernel=poly .....................................\n",
      "[CV] ......... C=100, gamma=1, kernel=poly, score=0.204, total=   0.9s\n",
      "[CV] C=100, gamma=1, kernel=sigmoid ..................................\n",
      "[CV] ...... C=100, gamma=1, kernel=sigmoid, score=0.548, total=   0.9s\n",
      "[CV] C=100, gamma=1, kernel=sigmoid ..................................\n",
      "[CV] ...... C=100, gamma=1, kernel=sigmoid, score=0.559, total=   0.9s\n",
      "[CV] C=100, gamma=1, kernel=sigmoid ..................................\n",
      "[CV] ...... C=100, gamma=1, kernel=sigmoid, score=0.557, total=   0.9s\n",
      "[CV] C=100, gamma=1, kernel=sigmoid ..................................\n",
      "[CV] ...... C=100, gamma=1, kernel=sigmoid, score=0.539, total=   1.0s\n",
      "[CV] C=100, gamma=1, kernel=sigmoid ..................................\n",
      "[CV] ...... C=100, gamma=1, kernel=sigmoid, score=0.546, total=   0.9s\n",
      "[CV] C=100, gamma=0.1, kernel=linear .................................\n",
      "[CV] ..... C=100, gamma=0.1, kernel=linear, score=0.559, total=   0.9s\n",
      "[CV] C=100, gamma=0.1, kernel=linear .................................\n",
      "[CV] ..... C=100, gamma=0.1, kernel=linear, score=0.555, total=   0.9s\n",
      "[CV] C=100, gamma=0.1, kernel=linear .................................\n",
      "[CV] ..... C=100, gamma=0.1, kernel=linear, score=0.561, total=   0.9s\n",
      "[CV] C=100, gamma=0.1, kernel=linear .................................\n",
      "[CV] ..... C=100, gamma=0.1, kernel=linear, score=0.543, total=   0.9s\n",
      "[CV] C=100, gamma=0.1, kernel=linear .................................\n",
      "[CV] ..... C=100, gamma=0.1, kernel=linear, score=0.550, total=   0.9s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.566, total=   0.9s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.555, total=   1.0s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.561, total=   1.0s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.539, total=   1.0s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.546, total=   1.0s\n",
      "[CV] C=100, gamma=0.1, kernel=poly ...................................\n",
      "[CV] ....... C=100, gamma=0.1, kernel=poly, score=0.096, total=   1.0s\n",
      "[CV] C=100, gamma=0.1, kernel=poly ...................................\n",
      "[CV] ....... C=100, gamma=0.1, kernel=poly, score=0.096, total=   0.9s\n",
      "[CV] C=100, gamma=0.1, kernel=poly ...................................\n",
      "[CV] ....... C=100, gamma=0.1, kernel=poly, score=0.100, total=   0.9s\n",
      "[CV] C=100, gamma=0.1, kernel=poly ...................................\n",
      "[CV] ....... C=100, gamma=0.1, kernel=poly, score=0.096, total=   1.0s\n",
      "[CV] C=100, gamma=0.1, kernel=poly ...................................\n",
      "[CV] ....... C=100, gamma=0.1, kernel=poly, score=0.096, total=   1.1s\n",
      "[CV] C=100, gamma=0.1, kernel=sigmoid ................................\n",
      "[CV] .... C=100, gamma=0.1, kernel=sigmoid, score=0.559, total=   1.1s\n",
      "[CV] C=100, gamma=0.1, kernel=sigmoid ................................\n",
      "[CV] .... C=100, gamma=0.1, kernel=sigmoid, score=0.555, total=   1.1s\n",
      "[CV] C=100, gamma=0.1, kernel=sigmoid ................................\n",
      "[CV] .... C=100, gamma=0.1, kernel=sigmoid, score=0.561, total=   1.2s\n",
      "[CV] C=100, gamma=0.1, kernel=sigmoid ................................\n",
      "[CV] .... C=100, gamma=0.1, kernel=sigmoid, score=0.543, total=   1.1s\n",
      "[CV] C=100, gamma=0.1, kernel=sigmoid ................................\n",
      "[CV] .... C=100, gamma=0.1, kernel=sigmoid, score=0.550, total=   1.2s\n",
      "[CV] C=100, gamma=0.01, kernel=linear ................................\n",
      "[CV] .... C=100, gamma=0.01, kernel=linear, score=0.559, total=   1.0s\n",
      "[CV] C=100, gamma=0.01, kernel=linear ................................\n",
      "[CV] .... C=100, gamma=0.01, kernel=linear, score=0.555, total=   1.1s\n",
      "[CV] C=100, gamma=0.01, kernel=linear ................................\n",
      "[CV] .... C=100, gamma=0.01, kernel=linear, score=0.561, total=   1.1s\n",
      "[CV] C=100, gamma=0.01, kernel=linear ................................\n",
      "[CV] .... C=100, gamma=0.01, kernel=linear, score=0.543, total=   1.0s\n",
      "[CV] C=100, gamma=0.01, kernel=linear ................................\n",
      "[CV] .... C=100, gamma=0.01, kernel=linear, score=0.550, total=   1.0s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.559, total=   1.1s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.555, total=   1.1s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.557, total=   1.1s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.543, total=   1.1s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.550, total=   1.1s\n",
      "[CV] C=100, gamma=0.01, kernel=poly ..................................\n",
      "[CV] ...... C=100, gamma=0.01, kernel=poly, score=0.096, total=   1.0s\n",
      "[CV] C=100, gamma=0.01, kernel=poly ..................................\n",
      "[CV] ...... C=100, gamma=0.01, kernel=poly, score=0.096, total=   1.0s\n",
      "[CV] C=100, gamma=0.01, kernel=poly ..................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...... C=100, gamma=0.01, kernel=poly, score=0.100, total=   1.0s\n",
      "[CV] C=100, gamma=0.01, kernel=poly ..................................\n",
      "[CV] ...... C=100, gamma=0.01, kernel=poly, score=0.096, total=   1.0s\n",
      "[CV] C=100, gamma=0.01, kernel=poly ..................................\n",
      "[CV] ...... C=100, gamma=0.01, kernel=poly, score=0.096, total=   1.0s\n",
      "[CV] C=100, gamma=0.01, kernel=sigmoid ...............................\n",
      "[CV] ... C=100, gamma=0.01, kernel=sigmoid, score=0.566, total=   1.0s\n",
      "[CV] C=100, gamma=0.01, kernel=sigmoid ...............................\n",
      "[CV] ... C=100, gamma=0.01, kernel=sigmoid, score=0.562, total=   1.0s\n",
      "[CV] C=100, gamma=0.01, kernel=sigmoid ...............................\n",
      "[CV] ... C=100, gamma=0.01, kernel=sigmoid, score=0.571, total=   1.1s\n",
      "[CV] C=100, gamma=0.01, kernel=sigmoid ...............................\n",
      "[CV] ... C=100, gamma=0.01, kernel=sigmoid, score=0.550, total=   1.1s\n",
      "[CV] C=100, gamma=0.01, kernel=sigmoid ...............................\n",
      "[CV] ... C=100, gamma=0.01, kernel=sigmoid, score=0.550, total=   1.1s\n",
      "[CV] C=100, gamma=0.001, kernel=linear ...............................\n",
      "[CV] ... C=100, gamma=0.001, kernel=linear, score=0.559, total=   1.0s\n",
      "[CV] C=100, gamma=0.001, kernel=linear ...............................\n",
      "[CV] ... C=100, gamma=0.001, kernel=linear, score=0.555, total=   1.0s\n",
      "[CV] C=100, gamma=0.001, kernel=linear ...............................\n",
      "[CV] ... C=100, gamma=0.001, kernel=linear, score=0.561, total=   1.0s\n",
      "[CV] C=100, gamma=0.001, kernel=linear ...............................\n",
      "[CV] ... C=100, gamma=0.001, kernel=linear, score=0.543, total=   1.0s\n",
      "[CV] C=100, gamma=0.001, kernel=linear ...............................\n",
      "[CV] ... C=100, gamma=0.001, kernel=linear, score=0.550, total=   1.0s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.153, total=   1.0s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.160, total=   1.1s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.154, total=   1.1s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.139, total=   1.0s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.171, total=   1.0s\n",
      "[CV] C=100, gamma=0.001, kernel=poly .................................\n",
      "[CV] ..... C=100, gamma=0.001, kernel=poly, score=0.096, total=   1.0s\n",
      "[CV] C=100, gamma=0.001, kernel=poly .................................\n",
      "[CV] ..... C=100, gamma=0.001, kernel=poly, score=0.096, total=   1.0s\n",
      "[CV] C=100, gamma=0.001, kernel=poly .................................\n",
      "[CV] ..... C=100, gamma=0.001, kernel=poly, score=0.100, total=   1.0s\n",
      "[CV] C=100, gamma=0.001, kernel=poly .................................\n",
      "[CV] ..... C=100, gamma=0.001, kernel=poly, score=0.096, total=   1.0s\n",
      "[CV] C=100, gamma=0.001, kernel=poly .................................\n",
      "[CV] ..... C=100, gamma=0.001, kernel=poly, score=0.096, total=   1.0s\n",
      "[CV] C=100, gamma=0.001, kernel=sigmoid ..............................\n",
      "[CV] .. C=100, gamma=0.001, kernel=sigmoid, score=0.096, total=   1.0s\n",
      "[CV] C=100, gamma=0.001, kernel=sigmoid ..............................\n",
      "[CV] .. C=100, gamma=0.001, kernel=sigmoid, score=0.096, total=   1.0s\n",
      "[CV] C=100, gamma=0.001, kernel=sigmoid ..............................\n",
      "[CV] .. C=100, gamma=0.001, kernel=sigmoid, score=0.104, total=   1.0s\n",
      "[CV] C=100, gamma=0.001, kernel=sigmoid ..............................\n",
      "[CV] .. C=100, gamma=0.001, kernel=sigmoid, score=0.096, total=   1.1s\n",
      "[CV] C=100, gamma=0.001, kernel=sigmoid ..............................\n",
      "[CV] .. C=100, gamma=0.001, kernel=sigmoid, score=0.096, total=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 320 out of 320 | elapsed:  5.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
       "                           class_weight=None, coef0=0.0,\n",
       "                           decision_function_shape='ovr', degree=3,\n",
       "                           gamma='scale', kernel='rbf', max_iter=-1,\n",
       "                           probability=False, random_state=None, shrinking=True,\n",
       "                           tol=0.001, verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'C': [0.1, 1, 10, 100], 'gamma': [1, 0.1, 0.01, 0.001],\n",
       "                         'kernel': ['linear', 'rbf', 'poly', 'sigmoid']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=3)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'C': [0.1,1, 10, 100], \n",
    "              'gamma': [1,0.1,0.01,0.001],\n",
    "              'kernel': ['linear', 'rbf', 'poly', 'sigmoid']}\n",
    "\n",
    "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3) \n",
    "  \n",
    "# fitting the model for grid search \n",
    "grid.fit(X_train_tfidf, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1, 'gamma': 1, 'kernel': 'linear'}\n",
      "SVC(C=1, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma=1, kernel='linear',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "# print best parameter after tuning \n",
    "print(grid.best_params_) \n",
    "\n",
    "# print how our model looks after hyper-parameter tuning \n",
    "print(grid.best_estimator_) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing the best parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svc(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    svc_fit = Pipeline([('vect', CountVectorizer()),\n",
    "                  ('tfidf', TfidfTransformer()),\n",
    "                  ('model', SVC(C=1, gamma=1, kernel='linear')),\n",
    "                 ])\n",
    "    svc_fit.fit(X_train, y_train)    # Fitting the data to the trianing data\n",
    "    \n",
    "    # Making Predictions on the test data\n",
    "    y_pred = svc_fit.predict(X_test)\n",
    "    acc = accuracy_score(y_pred=y_pred, y_true=y_test)\n",
    "    print(\"Model Accuracy: {}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate SVC Model\n",
      "Model Accuracy: 0.6129032258064516\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluate SVC Model\")\n",
    "svc(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us a 62% accuracy which is the best so far and I will go with this for now. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Model Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid which will include the parameters we will be testing\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': [True, False],\n",
      " 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None],\n",
      " 'max_features': ['auto', 'sqrt'],\n",
      " 'min_samples_leaf': [1, 2, 4],\n",
      " 'min_samples_split': [2, 5, 10],\n",
      " 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}\n"
     ]
    }
   ],
   "source": [
    "# Look at the parameter list\n",
    "from pprint import pprint\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 10.7min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 21.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score=nan,\n",
       "                   estimator=RandomForestClassifier(bootstrap=True,\n",
       "                                                    ccp_alpha=0.0,\n",
       "                                                    class_weight=None,\n",
       "                                                    criterion='gini',\n",
       "                                                    max_depth=None,\n",
       "                                                    max_features='auto',\n",
       "                                                    max_leaf_nodes=None,\n",
       "                                                    max_samples=None,\n",
       "                                                    min_impurity_decrease=0.0,\n",
       "                                                    min_impurity_split=None,\n",
       "                                                    min_samples_leaf=1,\n",
       "                                                    min_samples_split=2,\n",
       "                                                    min_weight_fraction_leaf=0.0,\n",
       "                                                    n_estimators=100,\n",
       "                                                    n_jobs...\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110,\n",
       "                                                      None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [200, 400, 600, 800,\n",
       "                                                         1000, 1200, 1400, 1600,\n",
       "                                                         1800, 2000]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=2)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' TAKES TIME TO EXECUTE SO SHOULDN'T EXECUTE AGAIN\n",
    "# Use the random grid to search for best hyperparameters\n",
    "\n",
    "# First create the base model to tune\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "\n",
    "rf_random.fit(X_train_tfidf, y_train)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate Model performance\n",
    "def evaluate(model, test_features, test_labels):\n",
    "    predictions = model.predict(test_features)\n",
    "    accuracy = accuracy_score(y_pred=predictions, y_true=test_labels)\n",
    "    print('Model Performance')\n",
    "    print('Accuracy = {:0.2f}%.'.format(accuracy))\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance\n",
      "Accuracy = 0.44%.\n"
     ]
    }
   ],
   "source": [
    "# # Preparing test data\n",
    "# X_test_counts = count_vec.transform(X_test)\n",
    "# X_test_tfidf = tfidf_trans.transform(X_test_counts)\n",
    "# base_model = RandomForestClassifier(n_estimators = 10, random_state = 42)\n",
    "# base_model.fit(X_train_tfidf, y_train)\n",
    "# base_accuracy = evaluate(base_model, X_test_tfidf , y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance\n",
      "Accuracy = 0.52%.\n"
     ]
    }
   ],
   "source": [
    "# best_random = rf_random.best_estimator_\n",
    "# random_accuracy = evaluate(best_random, X_test_tfidf , y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I still get a 52% accuracy so I will go for an SVC model instead. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model for Deployment\n",
    "Joblib is part of the SciPy ecosystem and provides utilities for pipelining Python jobs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('tfidf',\n",
       "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
       "                                  sublinear_tf=False, use_idf=True)),\n",
       "                ('model',\n",
       "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nb_fit = Pipeline([('vect', CountVectorizer()),\n",
    "#                   ('tfidf', TfidfTransformer()),\n",
    "#                   ('model', MultinomialNB()),\n",
    "#                  ])\n",
    "# nb_fit.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['final_model.sav']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib \n",
    "\n",
    "filename = 'final_model.sav'\n",
    "joblib.dump(best_random, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
